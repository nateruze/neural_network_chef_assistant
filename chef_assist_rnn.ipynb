{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_29344484.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below installations might be required"
      ],
      "metadata": {
        "id": "zRrbQwdkXzFL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "4FuW-3teXara",
        "outputId": "744d9fd8-df14-4e42-a6da-22ef05715910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 63.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: regex, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.7 regex-2022.4.24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "regex"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "!pip install -U nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# PLEASE RESTART RUNTIME BEFORE AFTER DOWNLOAD FOR METEOR_SCORE FUNCTION TO WORK!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# switch to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8XCbj17yX1Uk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "%cd/gdrive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5MudjgPX9d-",
        "outputId": "69f63758-af6b-455b-8f17-5606977a6076"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# function to remove punctuation\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "o5_2a40jYA7e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read txt files in\n",
        "\n",
        "with open('files_1_4.txt','r') as infile:\n",
        "    training_files_1to4 = infile.read()\n",
        "    tranining_data_ascii = unicodeToAscii(training_files_1to4.lower())\n",
        "    training_data = tranining_data_ascii.strip().split('end recipe') # a list where each element is a recipe unit\n",
        "    training_data = training_data[:-1] # pop last item in the list as it is an empty item\n",
        "\n",
        "with open('dev_files_10_14.txt','r') as infile:\n",
        "    dev_files_10to17 = infile.read()\n",
        "    dev_data_ascii = unicodeToAscii(dev_files_10to17.lower())\n",
        "    dev_data = dev_data_ascii.strip().split('end recipe') # a list where each element is a recipe unit\n",
        "    dev_data = dev_data[:-1] # pop last item in the list as it is an empty item\n",
        "\n",
        "with open('test_files_15_18.txt','r') as infile:\n",
        "    test_files_1to4 = infile.read()\n",
        "    test_data_ascii = unicodeToAscii(test_files_1to4.lower())\n",
        "    test_data = test_data_ascii.strip().split('end recipe') # a list where each element is a recipe unit\n",
        "    test_data = test_data[:-1] # pop last item in the list as it is an empty item\n",
        "\n",
        "with open('sample_txt.txt','r') as infile:\n",
        "    sample_txt = infile.read()\n",
        "    sample_text_ascii = unicodeToAscii(sample_txt.lower())\n",
        "    sample_data = sample_text_ascii.strip().split('end recipe') # a list where each element is a recipe unit\n",
        "    sample_data = sample_data[:-1] # pop last item in the list as it is an empty item"
      ],
      "metadata": {
        "id": "yG8RkqYdYLu3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "amm_3ul5Z_1p"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "J66px17NZ_uc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare global variables"
      ],
      "metadata": {
        "id": "lOhBqFjhYW2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 150\n",
        "teacher_forcing_ratio = 1.0\n",
        "hidden_size = 256"
      ],
      "metadata": {
        "id": "oJZlG_4KYY6O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The helper class below creates and stores indices of input/output to be used by tensors later."
      ],
      "metadata": {
        "id": "9quhryJ0Yf8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Indexed:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "XO8VPpFGYUkK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 1 "
      ],
      "metadata": {
        "id": "bBIcmpPfZAWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function below reads in recipes and outputs ingredient object, recipe object and a list of ingredient-recipe pairs."
      ],
      "metadata": {
        "id": "_7-KHgL3Ze47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readRecipe(txt_file):\n",
        "  ingRecPair = [] # initialise a list to store ingredient-recipe pairs\n",
        "  \n",
        "\n",
        "  for recipe in txt_file: # iters through each recipe unit\n",
        "\n",
        "    tmp_ingRecPair = []\n",
        "\n",
        "    temp_txt = recipe.strip().split('\\n')\n",
        "    \n",
        "    ingredient = ''.join(temp_txt[3:4])\n",
        "    \n",
        "    ingredient_cleaned = normalizeString(ingredient)\n",
        "    tmp_ingRecPair.append(ingredient_cleaned)\n",
        "\n",
        "    recipe_desc = ''.join(temp_txt[4:])\n",
        "    recipe_desc_cleaned = normalizeString(recipe_desc)\n",
        "    \n",
        "    tmp_ingRecPair.append(recipe_desc_cleaned)\n",
        "\n",
        "    ingRecPair.append(tmp_ingRecPair)\n",
        "\n",
        "  \n",
        "\n",
        "  input_ingredients = Indexed('ingredient')\n",
        "  output_recipe = Indexed('recipe')\n",
        "\n",
        "  \n",
        "\n",
        "  for pair in ingRecPair: # iters through each ingredient-recipe pair and cumulatively adds to ingredient and recipe classes respectively\n",
        "    \n",
        "    input_ingredients.addSentence(pair[0])\n",
        "   \n",
        "    output_recipe.addSentence(pair[1])\n",
        "\n",
        "    \n",
        "\n",
        "  return input_ingredients, output_recipe, ingRecPair\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "lTO_-MXkZLum"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise ingredient object, recipe object and ingredient-recipe pairs for each data set\n",
        "\n",
        "train_input_ingredient, train_output_recipe, train_pairs = readRecipe(training_data)\n",
        "dev_input_ingredient, dev_output_recipe, dev_pairs = readRecipe(dev_data)\n",
        "test_input_ingredient, test_output_recipe, test_pairs = readRecipe(test_data)\n"
      ],
      "metadata": {
        "id": "mUVkqjCUZsw9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running plot for train data -- run this when plotting for train data"
      ],
      "metadata": {
        "id": "MhPSggRmbjCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(train_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(train_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "wMxQRTTJaG2k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "wep1RrKRab2i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "UQBJz9SNaf17"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(1)\n",
        "    target_length = target_tensor.size(1)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True #if random.random() <= teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    #loss_output = loss.item() / target_length\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "jWOo5t8Dandb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_pairs)) \n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        #print(input_tensor)\n",
        "        target_tensor = training_pair[1]\n",
        "        #print(target_tensor)\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "dLveLATza0ed"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model1_train = EncoderRNN(train_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model1_train = DecoderRNN(hidden_size, train_output_recipe.n_words).to(device)\n"
      ],
      "metadata": {
        "id": "g0jGDdlFbJI8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_one_plot_loss_train = trainIters(encoder_model1_train, decoder_model1_train, 20000, print_every=1000)\n",
        "print(bm_one_plot_loss_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-5TlfjPbUMB",
        "outputId": "f7de5ce2-e37e-46ea-8dcb-f7d9f5bd076e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 5s (- 39m 51s) (1000 5%) 10.2531\n",
            "4m 13s (- 38m 1s) (2000 10%) 8.2282\n",
            "7m 2s (- 39m 56s) (3000 15%) 6.7074\n",
            "9m 52s (- 39m 29s) (4000 20%) 6.2514\n",
            "12m 43s (- 38m 9s) (5000 25%) 6.5175\n",
            "15m 34s (- 36m 21s) (6000 30%) 6.1178\n",
            "18m 26s (- 34m 15s) (7000 35%) 6.4667\n",
            "21m 18s (- 31m 58s) (8000 40%) 6.1216\n",
            "24m 15s (- 29m 39s) (9000 45%) 6.3540\n",
            "27m 14s (- 27m 14s) (10000 50%) 6.3665\n",
            "30m 18s (- 24m 47s) (11000 55%) 6.2205\n",
            "33m 7s (- 22m 5s) (12000 60%) 6.4334\n",
            "36m 12s (- 19m 29s) (13000 65%) 6.7658\n",
            "39m 17s (- 16m 50s) (14000 70%) 6.6474\n",
            "42m 19s (- 14m 6s) (15000 75%) 6.4973\n",
            "45m 29s (- 11m 22s) (16000 80%) 6.3281\n",
            "48m 46s (- 8m 36s) (17000 85%) 6.1626\n",
            "52m 8s (- 5m 47s) (18000 90%) 6.2829\n",
            "55m 27s (- 2m 55s) (19000 95%) 5.9023\n",
            "58m 39s (- 0m 0s) (20000 100%) 6.8721\n",
            "[10.786120495200157, 9.950586313009262, 10.241034578979015, 9.963319687843322, 10.361198716163635, 10.53011098742485, 10.262799232006072, 9.753206788897515, 10.076771465986967, 10.605815970897675, 10.71353937625885, 11.215103800296783, 8.88976743876934, 8.221422629058361, 9.019803442955016, 7.562892377376556, 6.791876028776169, 7.015565827488899, 6.94422114789486, 5.907635279893875, 7.4156406599283216, 5.966300385594368, 6.505150606632233, 6.888373846411705, 6.2776936447620395, 6.561750299930573, 7.165369225144386, 6.828381645679474, 7.205965890884399, 6.259627103209495, 6.461193196177483, 6.900920432806015, 5.442431173324585, 6.231709743142128, 6.104739159345627, 6.373542736768723, 5.986693646907806, 6.932540010213852, 5.95035195350647, 6.12948149561882, 6.388737882375717, 6.345580179691314, 6.696183793544769, 6.093630378246307, 6.567696802616119, 6.847863655686378, 7.040214301943779, 6.742759449481964, 5.929139213562012, 6.523160938024521, 7.155278351306915, 5.752325201034546, 6.170677388906479, 6.462450781464577, 5.671516935825348, 6.015169190168381, 6.341362793445587, 6.073445037603379, 5.608474037647247, 5.926936019659042, 6.399853564500809, 5.643629393577576, 6.312785124778747, 6.914526582360268, 6.404097232818604, 6.858595186471939, 6.270158710479737, 7.080061680078506, 6.900101093053817, 5.882929881811142, 5.785831556320191, 6.0666132551431655, 5.861957441568375, 6.225740076303482, 6.742385128736496, 6.382067133188247, 6.351310732364655, 5.63214461684227, 6.415814428329468, 5.7524784302711485, 5.7069867539405825, 6.419133102297783, 5.742044560909271, 7.019073053002358, 6.461668881177903, 6.139063693284989, 6.814433507919311, 6.372024626731872, 6.291892083883286, 6.573230383396148, 6.215100462436676, 6.69789818406105, 6.699648212194443, 6.964784972667694, 6.289802672863007, 6.329099764823914, 6.411631183028221, 5.952460774183273, 5.997953515052796, 6.107013443112374, 6.393678412437439, 5.540835101604461, 6.7681114757061005, 6.06776962518692, 6.146684995889664, 5.8959354013204575, 6.3792891490459445, 6.302413464784622, 6.564206562042236, 6.146142055988312, 5.779974380731582, 6.350140089988709, 6.4332261765003205, 5.428883485794067, 6.6256919193267825, 6.1646432161331175, 7.570817598104477, 6.042270090579986, 7.215438997745514, 6.722781615257263, 6.617066694498062, 6.824943350553513, 7.56540755033493, 7.091276557445526, 6.243989436626435, 6.831312251091004, 6.443542233705521, 6.352516185045243, 7.374023357629776, 6.313545140028, 7.233675383925438, 6.406053757667541, 6.4223795509338375, 6.739186061620712, 6.59629652440548, 6.478346297740936, 6.607441904544831, 6.587583436965942, 7.0091281056404116, 6.393697093725205, 6.230496366024017, 6.6259954333305355, 6.5950335597991945, 6.328584510087967, 7.02793642282486, 6.588401352167129, 6.516753573417663, 6.373457320928574, 6.303547253608704, 6.382800576686859, 6.632692211270332, 6.385054277181625, 7.396041789650917, 5.101749290823936, 6.302493838071823, 6.560311008691787, 6.468569304943085, 5.740044907331467, 6.7948519122600555, 5.899004452228546, 6.384416859149933, 5.923948898315429, 6.066186723709106, 6.765795021057129, 6.105852992534637, 6.172299928665161, 5.770175048708916, 6.1824847847223285, 6.078941108286381, 6.176385315656662, 6.3327563345432285, 5.833502802550793, 6.542705268859863, 6.663301991224289, 5.814880599975586, 6.514285361766815, 7.2825670629739765, 5.427788369655609, 6.153260147571563, 6.263811175823212, 6.029586632847786, 5.864763035774231, 6.333080059289932, 5.636003116965294, 5.284861641526223, 5.776406407356262, 5.1473585689067844, 6.969466832280159, 6.191972699165344, 5.789570840597153, 6.049764684438705, 6.3321028625965115, 6.810528032779693, 6.447334469556808, 7.829240328073501, 7.095909551978111, 6.931267845630646, 7.470293300151825, 7.02319269657135, 6.731198434233665]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for dev data "
      ],
      "metadata": {
        "id": "qZ0WUeaabszp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(dev_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(dev_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "zUYtyxjgbqEc"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(dev_pairs)) \n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        #print(input_tensor)\n",
        "        target_tensor = training_pair[1]\n",
        "        #print(target_tensor)\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "FGs2rVzocewh"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model1_dev = EncoderRNN(dev_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model1_dev = DecoderRNN(hidden_size, dev_output_recipe.n_words).to(device)"
      ],
      "metadata": {
        "id": "eTT1MiNdbSFP"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_one_plot_loss_dev = trainIters(encoder_model1_dev, decoder_model1_dev, 20000, print_every=1000)\n",
        "print(bm_one_plot_loss_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HqlVdZnbdNP",
        "outputId": "0c72609e-2ee8-4885-c458-d4c3fdc52766"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 27s (- 8m 40s) (1000 5%) 5.0299\n",
            "0m 55s (- 8m 19s) (2000 10%) 4.4572\n",
            "1m 26s (- 8m 10s) (3000 15%) 4.1815\n",
            "1m 57s (- 7m 51s) (4000 20%) 4.0370\n",
            "2m 29s (- 7m 27s) (5000 25%) 3.9859\n",
            "3m 0s (- 7m 2s) (6000 30%) 4.0016\n",
            "3m 32s (- 6m 34s) (7000 35%) 3.9630\n",
            "4m 3s (- 6m 5s) (8000 40%) 3.9668\n",
            "4m 35s (- 5m 37s) (9000 45%) 4.0196\n",
            "5m 7s (- 5m 7s) (10000 50%) 4.0080\n",
            "5m 40s (- 4m 38s) (11000 55%) 3.9908\n",
            "6m 13s (- 4m 8s) (12000 60%) 4.0038\n",
            "6m 46s (- 3m 38s) (13000 65%) 3.9651\n",
            "7m 19s (- 3m 8s) (14000 70%) 3.8958\n",
            "7m 54s (- 2m 38s) (15000 75%) 3.9531\n",
            "8m 30s (- 2m 7s) (16000 80%) 3.9859\n",
            "9m 8s (- 1m 36s) (17000 85%) 3.9167\n",
            "9m 45s (- 1m 5s) (18000 90%) 3.9689\n",
            "10m 23s (- 0m 32s) (19000 95%) 4.0028\n",
            "11m 2s (- 0m 0s) (20000 100%) 3.9956\n",
            "[6.637430275678635, 5.206529125869274, 4.970529796481133, 5.3092136216163635, 5.02588788330555, 5.185980479717255, 4.811426609754562, 4.421689612865448, 4.556514211893082, 4.174174370765686, 4.220243608951568, 4.682569000720978, 4.139259757995606, 4.376613700389862, 4.2085403263568875, 4.1841906440258025, 4.172876106500626, 5.162906517982483, 4.771020272970199, 4.653654606342315, 4.32424861073494, 4.082040550708771, 4.250536863803863, 4.170784854888916, 4.228657038211822, 4.236548355817795, 4.227641342878342, 4.110615764856338, 4.050968589782715, 4.1333548295497895, 3.839680941104889, 4.2785112881660465, 4.1401736557483675, 4.177703944444656, 3.913379529714584, 3.9580821418762206, 3.97474534034729, 4.078816430568695, 4.011299433708191, 3.9974832558631896, 4.1643913400173185, 4.05667058467865, 3.849402816295624, 4.034239387512207, 3.8081082916259765, 3.9945308816432954, 3.9820367920398714, 4.01441749215126, 3.993710036277771, 3.9618930506706236, 4.103118443489075, 3.7871268117427825, 4.104808262586594, 4.079741432666778, 4.036766737699509, 3.9919686627388002, 3.821686488389969, 4.0434087681770325, 4.078786327838897, 3.9686020541191103, 3.870335792303085, 4.16892905831337, 3.9511855673789977, 3.9306881284713744, 3.890139877796173, 4.1038228392601015, 3.9969652462005616, 3.7662725901603697, 3.8821561408042906, 4.069898020029068, 3.877862967252731, 3.980847809314728, 4.073444135189057, 3.8151156520843506, 3.9199306070804596, 4.15512225151062, 4.006737616062164, 3.9217734003067015, 4.048256328105927, 3.869267121553421, 3.9428375649452208, 4.204445216655731, 3.8937279272079466, 3.8789358043670656, 4.1454112637043, 3.8431097769737246, 4.020498180389405, 4.094824645519257, 4.229415261745453, 3.9432816457748414, 3.952895175218582, 4.114044919013977, 3.8587277865409852, 4.098270454406738, 3.9210078179836274, 3.9453900873661043, 4.081620634794235, 3.9580944204330444, 4.043758637905121, 4.106085307598114, 3.966169261932373, 3.9552241826057433, 4.1214946782588955, 3.9206014132499694, 4.126207274198532, 3.9189085268974306, 4.219707927703857, 3.8860293006896973, 3.787059180736542, 4.006200847625732, 4.004117932319641, 3.9969526493549346, 4.162727936506271, 4.178250591754914, 3.9590490007400514, 3.807418521642685, 3.907597143650055, 4.224958908557892, 3.9103271555900574, 3.8868501782417297, 3.876128784418106, 3.9317872500419617, 3.9850260114669798, 3.927089295387268, 3.9273477005958557, 3.87610396027565, 4.035365277528763, 4.024966762065888, 4.064998737573624, 4.002553374767303, 3.926534606218338, 3.697206516265869, 3.740831594467163, 4.043717904090881, 3.9136109697818755, 3.990914189815521, 3.7968749582767485, 3.93832909822464, 3.9660221910476685, 3.9443936455249786, 3.9100868022441864, 3.7748429262638092, 4.044857306480408, 4.116437711715698, 3.9148385953903198, 3.9311125826835633, 3.867720731496811, 4.021632101535797, 4.011937508583069, 3.937513288259506, 3.866223633289337, 3.879595412015915, 4.044353055953979, 4.056820707321167, 4.146285974979401, 4.016704217195511, 3.8624119114875795, 3.957013019323349, 4.10099491238594, 3.928673188686371, 4.044300048351288, 3.988636543750763, 3.910107614994049, 4.012382899522781, 3.7734574234485625, 3.9623131203651427, 3.8605743682384492, 3.7566710114479065, 3.8854898250103, 3.9734052383899687, 4.145643558502197, 4.017852420806885, 4.04347775220871, 3.845279712677002, 3.8967872142791746, 3.807371017932892, 3.9860163259506227, 4.0762493658065795, 3.895347888469696, 3.97465407371521, 4.097620408535004, 4.06104110956192, 3.9596579682827, 3.929441092014313, 4.009430751800537, 3.988149347305298, 4.022362362146378, 3.883375811576843, 4.0749751496315, 4.001915466785431, 3.8957940983772277, 3.961197022199631, 3.9741846895217896, 3.9872403609752656, 4.0376092100143435, 4.091022765636444, 3.846097928285599, 3.980623779296875, 4.083786050081253, 4.097957466840744]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 1 Evaluation"
      ],
      "metadata": {
        "id": "cqIVnMeZciam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(test_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(test_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "nfSfkXKtdoWA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "9YPN-vBbeLTX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "EW0fVFYbePc-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(test_input_ingredient, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(test_output_recipe.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "FFc8vsYNcuJl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateQuantitatively(encoder, decoder, n=80):\n",
        "  bm_one_bleu = []\n",
        "  bm_one_meteor = []\n",
        "  matched_words = 0\n",
        "  extra_words = 0\n",
        "\n",
        "  train_pair_subset = test_pairs\n",
        "\n",
        "\n",
        "  for i in range(n):\n",
        "      pair = random.choice(train_pair_subset)\n",
        "      #print('>', pair[0])\n",
        "      #print('=', pair[1])\n",
        "      output_words= evaluate(encoder, decoder, pair[0])\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      #print('<', output_sentence)\n",
        "      #print('')\n",
        "\n",
        "      bleu_score = nltk.translate.bleu_score.sentence_bleu(pair[1], output_sentence) \n",
        "      bm_one_bleu.append(bleu_score)\n",
        "\n",
        "      hypothesis = nltk.word_tokenize(output_sentence)\n",
        "\n",
        "      reference = nltk.word_tokenize(pair[1])\n",
        "\n",
        "\n",
        "      meteor_score = nltk.translate.meteor_score.single_meteor_score(reference, hypothesis)\n",
        "\n",
        "\n",
        "      bm_one_meteor.append(meteor_score)\n",
        "\n",
        "      matched = 0\n",
        "      extra = 0\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word in reference:\n",
        "          matched += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      matched_words += matched\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word not in reference:\n",
        "          extra += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      extra_words += extra\n",
        "\n",
        "  \n",
        "\n",
        "      train_pair_subset.remove(pair)\n",
        "  \n",
        "\n",
        "  \n",
        "  return bm_one_bleu, bm_one_meteor, matched_words, extra_words"
      ],
      "metadata": {
        "id": "37_gXWmccvBq"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model1_test = EncoderRNN(test_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model1_test = DecoderRNN(hidden_size, test_output_recipe.n_words).to(device)"
      ],
      "metadata": {
        "id": "oZ760wS9dBzE"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu, meteor, avg_match, avg_extra = (evaluateQuantitatively(encoder_model1_test, decoder_model1_test))\n",
        "print(np.mean(bleu))\n",
        "print(np.mean(meteor))\n",
        "print(np.mean(avg_match))\n",
        "print(np.mean(avg_extra))\n",
        "print(avg_extra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkxz9OrFc3tX",
        "outputId": "62724aa0-4ded-41f0-8d6f-492f23d4fa0c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.092999976453642e-232\n",
            "0.00844528785916179\n",
            "326.0\n",
            "11674.0\n",
            "11674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 2"
      ],
      "metadata": {
        "id": "2zlEqKM1fn-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for train data"
      ],
      "metadata": {
        "id": "ru9u4o4ojgdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(train_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(train_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "y24BsZ3EfvcD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "K410pT0fjD9E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #return hidden\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "SzOFhW57jFHk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(1)\n",
        "    target_length = target_tensor.size(1)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True #if random.random() <= teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ],
      "metadata": {
        "id": "xL2BzS0ijIju"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "uWvPjy6RjOZb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model2_train = EncoderRNN(train_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model2_train = AttnDecoderRNN(hidden_size, train_output_recipe.n_words, dropout_p=0.1).to(device)"
      ],
      "metadata": {
        "id": "HvM8GQf0jP3I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_two_plot_loss_train = trainIters_attn(encoder_model2_train, decoder_model2_train, 20000, print_every=1000)\n",
        "print(bm_two_plot_loss_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsIglmWqjWs7",
        "outputId": "9a4e3758-a432-46c7-ec06-0bd67dc10a7c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 11s (- 41m 47s) (1000 5%) 7.3467\n",
            "5m 9s (- 46m 22s) (2000 10%) 6.9501\n",
            "8m 4s (- 45m 42s) (3000 15%) 6.9247\n",
            "11m 8s (- 44m 34s) (4000 20%) 6.9669\n",
            "14m 15s (- 42m 47s) (5000 25%) 7.1350\n",
            "17m 23s (- 40m 34s) (6000 30%) 7.3081\n",
            "20m 33s (- 38m 10s) (7000 35%) 7.0395\n",
            "23m 45s (- 35m 38s) (8000 40%) 8.0514\n",
            "26m 59s (- 32m 58s) (9000 45%) 7.7955\n",
            "30m 12s (- 30m 12s) (10000 50%) 7.5170\n",
            "33m 26s (- 27m 22s) (11000 55%) 7.5357\n",
            "36m 41s (- 24m 27s) (12000 60%) 7.7338\n",
            "39m 55s (- 21m 29s) (13000 65%) 7.2962\n",
            "43m 9s (- 18m 29s) (14000 70%) 7.2364\n",
            "46m 22s (- 15m 27s) (15000 75%) 7.0838\n",
            "49m 36s (- 12m 24s) (16000 80%) 7.7688\n",
            "52m 51s (- 9m 19s) (17000 85%) 7.6399\n",
            "56m 6s (- 6m 14s) (18000 90%) 7.2795\n",
            "59m 20s (- 3m 7s) (19000 95%) 7.6794\n",
            "62m 34s (- 0m 0s) (20000 100%) 7.4104\n",
            "[9.388982267379761, 7.7777050852775576, 6.829488911032676, 6.969811614751816, 7.605687662363052, 6.577835032939911, 6.535099741220474, 7.29573949098587, 6.7983598709106445, 7.688174868226051, 7.01836980164051, 6.952175240516663, 7.563382929563522, 6.9039197862148285, 6.4862151992321015, 6.996308706998825, 6.961735602617264, 7.402749656438828, 6.085362829566002, 7.131202207803726, 6.594662891626358, 7.886023625135421, 7.7954463768005375, 6.402242485880851, 6.999588726758957, 6.598337265253067, 6.529973151683808, 7.5176193904876705, 6.586673747301102, 6.336730813980102, 7.495337357521057, 7.165498608350754, 6.4505780100822445, 6.163760108947754, 7.575384159088134, 7.208154183030128, 6.725911355018615, 6.685445338487625, 6.761697617769241, 7.437642226219177, 7.034579373002052, 6.4336235469579695, 7.6645242989063265, 6.494566187858582, 8.188588637113572, 7.331823353171348, 6.850116587877274, 6.897375590801239, 7.392452507019043, 7.062586280107499, 6.698193160891533, 7.042383127212524, 6.629448810815811, 7.8528392606973645, 7.460012016296386, 7.867207252979279, 7.909970817565918, 7.465676102638245, 7.298624852299691, 6.85670493721962, 6.599287534356117, 6.488849286437034, 7.548414933681488, 6.342323749661445, 6.794990816116333, 7.768968082666397, 6.746222611665726, 7.579920166730881, 7.093836041390896, 7.432211973667145, 7.400854835510254, 7.128760724663734, 8.05342505723238, 7.695913045406342, 8.486936138272286, 8.394648958742618, 7.899849245548248, 8.512935609817506, 8.368202773332596, 8.572250757217407, 9.254980775117874, 8.310585963726044, 6.841883922815323, 8.58238243728876, 6.940031198859215, 7.998791341185569, 7.509594713449478, 7.496409486532212, 7.536042355298996, 7.484014402627945, 7.526446788907051, 6.939985667467117, 8.220267480015755, 6.928944791555405, 7.177872642874718, 6.814958181977272, 8.25054660320282, 7.587119457125664, 7.3875850594043735, 8.335896764993668, 6.85890208080411, 7.688221904039383, 7.50759224832058, 7.053457851111889, 7.845324138104916, 7.478803125619888, 7.936536396741867, 8.07000170826912, 7.110784638226033, 7.807136694788933, 7.972779787182808, 7.116578612923622, 7.94713967859745, 7.474959335327148, 6.782245986461639, 7.691086109280587, 7.990018355846405, 8.822463009953498, 7.006621455550194, 8.533967742919922, 7.682611246258021, 6.9508682572841645, 7.2170807242393495, 7.425440005660057, 7.224669980406762, 7.09671563744545, 7.121293036341667, 7.887261831760407, 7.125407159328461, 7.230696648359299, 7.376811962127686, 6.657914416193962, 7.435781108736992, 7.705610485076904, 7.840342487096787, 7.510809448361397, 6.701185318231583, 6.805668186545372, 7.407772822380066, 6.922336863279343, 7.588804621696472, 8.125517575144768, 6.307926905155182, 6.642286378145218, 7.000174803137779, 6.371549212932587, 8.058622727394104, 6.430951300859451, 7.364582586586476, 6.947106572389603, 7.372242399454117, 7.4348409199714665, 8.02626456975937, 8.207050879001617, 8.697917311191558, 7.6168472629785535, 7.041642056703568, 7.853544523715973, 7.760836384892464, 7.676482759714126, 8.396893911361694, 7.356567025184631, 8.292323831319809, 7.3608663105964665, 6.520060148239136, 8.222982284426688, 7.430054186582566, 7.377839331626892, 7.975653477907181, 7.465981611609459, 7.0115944766998295, 7.9312744247913365, 6.7870738863945, 7.07470538854599, 7.250877768397332, 7.1141563707590105, 7.307174016833305, 7.887021743059158, 7.449605284929276, 6.981872623860836, 7.593931217193603, 7.710608183145523, 7.247664380669594, 8.05245301157236, 7.613370550870895, 7.756880974769592, 8.269792642593384, 6.987373079657555, 7.974193204641342, 7.587573268413544, 7.532438408136368, 8.696172103881835, 7.589760057032108, 7.142077125906944, 7.449847058653831, 6.46053974211216, 6.719857682585716, 7.504233164191246, 7.731519256234169, 7.277851711809635]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for dev data"
      ],
      "metadata": {
        "id": "M7nhA0AdjkOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(dev_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(dev_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "TUlbzw5gjlg7"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(dev_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "hHoke-P7jwuD"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model2_dev = EncoderRNN(dev_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model2_dev = AttnDecoderRNN(hidden_size, dev_output_recipe.n_words, dropout_p=0.1).to(device)"
      ],
      "metadata": {
        "id": "LuQklPzcj0Ur"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_two_plot_loss_dev = trainIters_attn(encoder_model2_dev, decoder_model2_dev, 20000, print_every=1000)\n",
        "print(bm_two_plot_loss_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4sUZK8Nj4L2",
        "outputId": "ae88b1d1-8724-491a-d75a-7cb1a5f68e01"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 33s (- 10m 45s) (1000 5%) 5.5698\n",
            "1m 16s (- 11m 27s) (2000 10%) 5.5025\n",
            "1m 57s (- 11m 8s) (3000 15%) 5.5132\n",
            "2m 39s (- 10m 37s) (4000 20%) 5.4038\n",
            "3m 24s (- 10m 12s) (5000 25%) 5.2486\n",
            "4m 9s (- 9m 42s) (6000 30%) 5.4147\n",
            "4m 55s (- 9m 8s) (7000 35%) 5.4143\n",
            "5m 40s (- 8m 30s) (8000 40%) 5.3850\n",
            "6m 25s (- 7m 51s) (9000 45%) 5.2645\n",
            "7m 11s (- 7m 11s) (10000 50%) 5.4218\n",
            "7m 58s (- 6m 31s) (11000 55%) 5.3566\n",
            "8m 44s (- 5m 49s) (12000 60%) 5.3786\n",
            "9m 30s (- 5m 7s) (13000 65%) 5.3084\n",
            "10m 16s (- 4m 24s) (14000 70%) 5.3820\n",
            "11m 2s (- 3m 40s) (15000 75%) 5.3937\n",
            "11m 48s (- 2m 57s) (16000 80%) 5.3734\n",
            "12m 33s (- 2m 13s) (17000 85%) 5.3848\n",
            "13m 19s (- 1m 28s) (18000 90%) 5.4083\n",
            "14m 6s (- 0m 44s) (19000 95%) 5.3798\n",
            "14m 52s (- 0m 0s) (20000 100%) 5.3747\n",
            "[7.255357525348663, 5.399887592196465, 5.713572088479996, 5.793259090185165, 5.391277334690094, 4.880471341013909, 5.329641517996788, 5.331783687472344, 5.21092274069786, 5.391756101250649, 5.215547366142273, 5.34411280632019, 5.044066809415817, 5.114803553819656, 5.509711149930954, 6.347118132710457, 5.881783083081245, 5.5123725938797, 5.81731907248497, 5.238312571048737, 5.767440881729126, 5.5073383736610415, 5.473658328056335, 5.561974232196808, 5.930737553834915, 5.481475800871849, 5.029365711212158, 5.544194390773773, 5.28703617811203, 5.549111182689667, 5.365567753314972, 5.457094074487686, 5.181799471378326, 5.416159095168114, 5.592567831873894, 5.54386402964592, 5.415951403379441, 5.511223731338978, 5.447387013435364, 5.106024693846702, 4.838380934298039, 5.42746324300766, 5.053848538994789, 5.377183085680008, 5.290047647953034, 5.287219421863556, 5.193067969083786, 5.197663558721542, 5.598584064841271, 5.22204567193985, 5.48139436006546, 4.9482767868041995, 5.430714339017868, 5.586059844493866, 5.405757966041565, 5.449783281087876, 5.443224566578865, 5.572645452022552, 5.2763015776872635, 5.552357611656189, 5.425538224577903, 5.275468831062317, 5.903756252527237, 5.078338461518288, 5.63023316681385, 5.35487350165844, 4.922378321290016, 5.2981800085306165, 5.685096271038056, 5.568883998990059, 5.248246036171913, 5.216766805052758, 5.779426341056824, 5.229699504375458, 5.448991779983044, 5.250662208795547, 5.359978731870651, 5.624029439687729, 5.262857558727265, 5.429755922555923, 5.366052471399307, 5.194397086501121, 5.026108596771955, 5.547355640530586, 5.078402383327484, 5.250528681278229, 5.100610785484314, 5.179525853395462, 5.51012601852417, 5.39193173289299, 5.258203146457672, 5.863059217333793, 5.474824194908142, 5.273926540613174, 5.315396834611892, 5.659608247280121, 5.399130640029907, 5.3988851702213285, 5.272189881801605, 5.302842937707901, 5.553319050073624, 5.719843801259994, 5.315653696358204, 5.145176058411598, 5.3995974826812745, 5.2967083501815795, 5.056208726465702, 5.05891655266285, 5.476262925863266, 5.54388213455677, 5.565853365659714, 5.46529048204422, 5.036683866381646, 5.478863098621368, 5.36875210762024, 5.686294764280319, 5.441297080516815, 4.944571452140808, 5.512315651476383, 5.286010385751724, 5.19777948975563, 5.5348404103517534, 5.310559420585633, 5.508382807970047, 5.3258159929513935, 5.512976899147033, 5.075251942276955, 5.376520880460739, 5.23883593916893, 5.0028695333004, 5.127181729972363, 5.736433945894241, 5.254048726558685, 5.50217670917511, 5.5203758347034455, 5.2283378446102144, 5.151696152091026, 5.5741207468509675, 5.283387962579727, 5.442416948080063, 5.324783889949321, 5.197398151159287, 5.633257797956467, 5.308692231178283, 5.486853125691414, 5.557641545534134, 5.371790933609009, 5.147042092978954, 5.876966651678085, 5.032553464174271, 5.438488669395447, 5.435045869350433, 5.484960638284683, 5.306094747781754, 4.988251923322678, 5.133098611831665, 5.287788569331169, 5.477934308052063, 5.504687547683716, 5.677437393665314, 5.230454726815224, 5.309036778211594, 5.535175634622574, 5.2596621370315555, 5.45258266210556, 5.463382484912873, 5.367638064622879, 5.501431032419204, 5.126129603087902, 5.602355493307114, 5.54656961530447, 5.1766218739748, 5.702430522441864, 5.4499886173009875, 5.325582234859467, 5.553249132633209, 5.642862888574601, 5.141058091521263, 4.970436109900475, 5.574223361611367, 5.413962647914887, 5.276094633340835, 5.3617184340953825, 5.2136343681812285, 5.3884114742279055, 5.253415340781212, 5.585623693466187, 5.359700818061828, 5.299846060872078, 5.6452753806114195, 5.419801646471024, 5.360870530605316, 5.615453068614006, 5.2168638211488725, 5.287312355041504, 5.669447010755539, 5.059701439142227, 5.175938882827759, 5.36005751490593, 5.581546176671981]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 2 Evaluation"
      ],
      "metadata": {
        "id": "eRLU1WxakF9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(test_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(test_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "DPA7CN3pkFUX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "J-V-NiZTkNTv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        #hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #return hidden\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "fdUllOSmkQWw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_attn(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(test_input_ingredient, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(test_output_recipe.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "fi8b03JSki3G"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly_attn(encoder, decoder, n=80):\n",
        "  bm_one_bleu = []\n",
        "  bm_one_meteor = []\n",
        "  matched_words = []\n",
        "  extra_words = []\n",
        "  train_pair_subset = test_pairs\n",
        "\n",
        "  for i in range(n):\n",
        "      pair = random.choice(test_pairs)\n",
        "      #print('>', pair[0])\n",
        "      #print('=', pair[1])\n",
        "      output_words, attention= evaluate_attn(encoder, decoder, pair[0])\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      #print('<', output_sentence)\n",
        "      #print('')\n",
        "\n",
        "      bleu_score = nltk.translate.bleu_score.sentence_bleu(pair[1], output_sentence) \n",
        "      bm_one_bleu.append(bleu_score)\n",
        "\n",
        "      hypothesis = nltk.word_tokenize(output_sentence)\n",
        "      #print(hypothesis)\n",
        "      reference = nltk.word_tokenize(pair[1])\n",
        "      #print(reference)\n",
        "\n",
        "      meteor_score = nltk.translate.meteor_score.single_meteor_score(reference, hypothesis)\n",
        "      #nltk.translate.meteor\n",
        "\n",
        "      bm_one_meteor.append(meteor_score)\n",
        "\n",
        "      matched = 0\n",
        "      extra = 0\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word in reference:\n",
        "          matched += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      matched_words.append(matched)\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word not in reference:\n",
        "          extra += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      extra_words.append(extra)\n",
        "\n",
        "  \n",
        "\n",
        "      train_pair_subset.remove(pair)\n",
        "  \n",
        "  #print(len(train_pair_subset))\n",
        "  \n",
        "  return bm_one_bleu, bm_one_meteor, matched_words, extra_words"
      ],
      "metadata": {
        "id": "NSlZiaElklRA"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model2_test = EncoderRNN(test_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model2_test = AttnDecoderRNN(hidden_size, test_output_recipe.n_words).to(device)"
      ],
      "metadata": {
        "id": "AFrG1BGvkqu-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a few prior functions (readRecipe, indexed, etc) need to be re-run for the below to work\n",
        "\n",
        "\n",
        "bleu, meteor, avg_match, avg_extra = (evaluateRandomly_attn(encoder_model2_test, decoder_model2_test))\n",
        "print(np.mean(bleu))\n",
        "print(np.mean(meteor))\n",
        "print(np.mean(avg_match))\n",
        "print(np.mean(avg_extra))\n",
        "print(avg_extra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f_wDXibktxb",
        "outputId": "bb21219c-496f-43b8-d1db-844718090b47"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.273983962868525e-232\n",
            "0.01129634003859691\n",
            "6.7625\n",
            "143.2375\n",
            "[147, 150, 150, 149, 150, 149, 150, 150, 148, 150, 150, 150, 148, 79, 148, 148, 150, 144, 149, 150, 150, 147, 150, 150, 146, 148, 150, 144, 150, 150, 150, 145, 149, 54, 70, 145, 149, 148, 150, 149, 150, 150, 150, 150, 130, 149, 144, 150, 149, 150, 150, 149, 94, 150, 145, 150, 148, 149, 149, 150, 150, 92, 150, 143, 149, 105, 150, 146, 150, 150, 150, 132, 150, 149, 150, 150, 149, 149, 149, 137]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 3 (pre-processed data)"
      ],
      "metadata": {
        "id": "h29DP-7SmMh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqEcnA96mQvF",
        "outputId": "e8a6f2c8-ef51-4518-d68f-4e5cd3f9aad3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessData(stringX, stringCategory):\n",
        "  \n",
        "  if stringCategory == \"ingredient\":\n",
        "    ingredient = True\n",
        "  else:\n",
        "    ingredient = False\n",
        "\n",
        "  filtered_pos = [\"NN\", \"NNS\"]\n",
        "\n",
        "\n",
        "  stringX = unicodeToAscii(stringX.lower().strip())\n",
        "  stringX = stringX.replace('\\t', ' ') # replace tabs with space\n",
        "  stringX = re.sub('[0-9]+', '', stringX) # remove numbers\n",
        "\n",
        "  #print(stringX)\n",
        "\n",
        "  punctuation = nltk.tokenize.RegexpTokenizer(r'\\w+') # strip punctuation \n",
        "  stringX_tokens = punctuation.tokenize(stringX) # tokenize words\n",
        "  #print(stringX_tokens)\n",
        "\n",
        "  stringX_tagged = nltk.pos_tag(stringX_tokens)\n",
        "  #print(stringX_tagged)\n",
        "\n",
        "  if ingredient:\n",
        "    for tpl in stringX_tagged:\n",
        "      if tpl[1] in filtered_pos:\n",
        "        pass\n",
        "      else:\n",
        "        stringX_tokens.remove(tpl[0])\n",
        "  else:\n",
        "    pass\n",
        "  \n",
        "  #print(stringX_tokens)\n",
        "\n",
        "  # filter out common cooking measurement units\n",
        "  stop_words = [\"ingredients\", \"tb\", \"tbs\", \"tbsp\", \"tsp\", \"can\", \"oz\", \"g\", \"l\", \"lb\", \"fl\", \"gal\", \"q\", \"qt\", \"c\", \"tbl\", \"pt\", \"ml\", \"pinch\", \"dash\",\n",
        "                \"cc\", \"kg\", \"dl\", \"gram\", \"mg\", \"or\", \"ts\", \"lb\", \"about\", \"abouts\"]\n",
        "\n",
        "  for word in stringX_tokens:\n",
        "    if word in stop_words:\n",
        "      stringX_tokens.remove(word)\n",
        "  \n",
        "  \n",
        "  cleaned_stringX = ' '.join(stringX_tokens)\n",
        "  \n",
        "  return cleaned_stringX"
      ],
      "metadata": {
        "id": "YeIjKSCNmmQV"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readRecipe_preprocessed(txt_file):\n",
        "  ingRecPair = [] # initialise a list to store ingredient-recipe pairs\n",
        "\n",
        "\n",
        "  for recipe in txt_file: # iters through each recipe unit\n",
        "\n",
        "    tmp_ingRecPair = []\n",
        "\n",
        "    temp_txt = recipe.strip().split('\\n')\n",
        "\n",
        "    ingredient = ''.join(temp_txt[3:4])\n",
        "\n",
        "    ingredient_cleaned = preprocessData(ingredient, \"ingredient\")\n",
        "    \n",
        "    #print(ingredient)\n",
        "    #print(ingredient_cleaned)\n",
        "    \n",
        "    tmp_ingRecPair.append(ingredient_cleaned)\n",
        "\n",
        "    recipe_desc = ''.join(temp_txt[4:])\n",
        "    recipe_desc_cleaned = preprocessData(recipe_desc, \"recipe\")\n",
        "\n",
        "    #print(recipe_desc)\n",
        "    #print(recipe_desc_cleaned)\n",
        "\n",
        "    tmp_ingRecPair.append(recipe_desc_cleaned)\n",
        "\n",
        "    ingRecPair.append(tmp_ingRecPair)\n",
        "\n",
        "  #print(ingRecPair)\n",
        "\n",
        "  input_ingredients = Indexed('ingredient')\n",
        "  output_recipe = Indexed('recipe')\n",
        "\n",
        "  #print(ingRecPair[-1])\n",
        "  #ingRecPairUpdated = ingRecPair[ : -1]\n",
        "\n",
        "  for pair in ingRecPair: # iters through each ingredient-recipe pair and cumulatively adds to ingredient and recipe classes respectively\n",
        "    \n",
        "    input_ingredients.addSentence(pair[0])\n",
        "   \n",
        "    output_recipe.addSentence(pair[1])\n",
        "\n",
        "  \n",
        "\n",
        "  return input_ingredients, output_recipe, ingRecPair"
      ],
      "metadata": {
        "id": "aJDd8R3Jmqgy"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ingredient, train_output_recipe, train_pairs = readRecipe_preprocessed(training_data)\n",
        "dev_input_ingredient, dev_output_recipe, dev_pairs = readRecipe_preprocessed(dev_data)\n",
        "test_input_ingredient, testoutput_recipe, test_pairs = readRecipe_preprocessed(test_data)"
      ],
      "metadata": {
        "id": "8Sr9vudGmtEz"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for train data"
      ],
      "metadata": {
        "id": "mI9rGve0ntUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(train_input_ingredient, pair[0]) # train_input_ingredient etc\n",
        "    target_tensor = tensorFromSentence(train_output_recipe, pair[1]) # train_output_recipe etc\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "WlspvLnpnudS"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "OGOaGaUmoRdQ"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "e0iF3gcsoUH3"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(1)\n",
        "    target_length = target_tensor.size(1)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True #if random.random() <= teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "-cM8WFOgnxbt"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #plt_points_list.append(plot_losses)\n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "n3MIWPAcn0c7"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder_model3_train = EncoderRNN(train_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model3_train = AttnDecoderRNN(hidden_size, train_output_recipe.n_words, dropout_p=0.1).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "okar6K5Cn35E"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_three_plot_loss_train = trainIters_attn(encoder_model3_train, decoder_model3_train, 20000, print_every=1000)\n",
        "print(bm_three_plot_loss_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG7u4EMFoCtH",
        "outputId": "49b14c66-1a4d-4e0b-84dd-3f2a39999769"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 56s (- 36m 53s) (1000 5%) 8.4146\n",
            "3m 55s (- 35m 20s) (2000 10%) 8.5541\n",
            "5m 54s (- 33m 29s) (3000 15%) 8.6518\n",
            "7m 53s (- 31m 34s) (4000 20%) 8.7903\n",
            "9m 53s (- 29m 40s) (5000 25%) 8.4743\n",
            "11m 53s (- 27m 45s) (6000 30%) 8.6309\n",
            "13m 54s (- 25m 50s) (7000 35%) 8.7366\n",
            "15m 55s (- 23m 53s) (8000 40%) 8.5881\n",
            "17m 56s (- 21m 55s) (9000 45%) 8.5801\n",
            "19m 58s (- 19m 58s) (10000 50%) 8.9647\n",
            "22m 0s (- 18m 0s) (11000 55%) 8.4395\n",
            "24m 2s (- 16m 1s) (12000 60%) 9.0846\n",
            "26m 4s (- 14m 2s) (13000 65%) 9.0100\n",
            "28m 5s (- 12m 2s) (14000 70%) 8.7768\n",
            "30m 6s (- 10m 2s) (15000 75%) 8.9503\n",
            "32m 8s (- 8m 2s) (16000 80%) 8.7007\n",
            "34m 10s (- 6m 1s) (17000 85%) 9.1075\n",
            "36m 13s (- 4m 1s) (18000 90%) 8.7246\n",
            "38m 15s (- 2m 0s) (19000 95%) 8.6921\n",
            "40m 16s (- 0m 0s) (20000 100%) 9.1263\n",
            "[9.156798487901687, 7.704951445311308, 7.769626179262996, 8.537768945284189, 8.580034768208861, 8.165053878128528, 8.446973920464515, 8.67271901898086, 8.206198983490467, 8.905613913834095, 8.307966793179512, 8.859887516363523, 7.763357540667057, 8.6133424113784, 8.030188243295997, 8.288325197286904, 8.65597889367491, 7.691017134459689, 9.66169031015048, 9.669216325804591, 7.503618690108414, 8.57640478014946, 9.086147911064327, 9.012488676905631, 8.126288202391006, 9.246115454314277, 9.03016643717885, 8.952685780897736, 8.436447951658629, 8.547706653773785, 9.334062929777428, 9.15899856198579, 8.079635779559613, 9.052458660764241, 9.035333109181375, 9.076720024036621, 8.129936296194792, 7.786469534784556, 8.973675734847784, 9.275584366247058, 9.014556703440611, 9.6505286272354, 9.019936406216583, 8.415762968957424, 7.167201608514879, 9.55580063469708, 8.196059511601925, 7.516445641293249, 8.08279662758112, 8.124051308862398, 9.74801394611597, 7.886393552409172, 8.585577910542488, 8.967723658391623, 8.884777930599903, 9.013547024950386, 8.308277772065049, 8.60971262017265, 8.395735231265427, 7.908822255093837, 8.79410008087023, 8.109871785752475, 8.316986619234084, 9.001965430667042, 8.728768455684184, 9.851602224735544, 9.11243737082812, 8.227113161422313, 8.009096753732447, 9.213961088048636, 9.131595673430711, 9.431952715236694, 8.249121002418397, 8.120878470141884, 8.1777596385777, 8.458595501473063, 8.728077433397994, 8.725133145023138, 8.30688656472048, 8.550535515286029, 8.245067321522475, 8.796410826444626, 9.227294180336466, 8.786358974426985, 7.6735829320177436, 7.761296134963632, 9.98028583959298, 9.329863658319228, 7.95557315947488, 8.045425692470213, 8.593818633556365, 8.45627690203488, 8.672213493464515, 9.724273076355376, 9.33039220124483, 8.455355953593074, 8.524823247790337, 10.177170633897186, 8.809091524302056, 8.903950642682611, 7.905028963018931, 8.582544678664998, 10.214938902445137, 7.4855619958788155, 8.722581450045109, 8.631552013908513, 7.953801433444023, 8.61467891484499, 7.38849522347562, 8.896104409811088, 10.439477907551627, 9.915793941318988, 8.964493318379972, 9.08799050888978, 8.668329673707484, 8.377191483052448, 9.34295593192568, 8.187232316972223, 9.032052847720514, 8.83079176902771, 10.121431460449385, 9.878154155855881, 9.298097724325343, 8.32921919329092, 9.584715985879303, 9.140955939599863, 7.926530231311918, 8.515034481883049, 8.163829612356926, 9.142449144728015, 8.519817989149452, 8.739342130050064, 8.43020747391967, 8.428747838176786, 9.173648259788752, 8.919846572756226, 9.319977711639368, 8.714880687089753, 8.484121112556895, 9.037427987620468, 8.932884427309036, 10.172596820890904, 7.630124521337275, 9.425448267119936, 8.458116236467822, 9.86122650663412, 9.119318924993276, 9.060060333078727, 7.957879757732153, 8.88533814670518, 9.463989873882383, 8.693020302005571, 9.102755436002827, 8.401238970011473, 8.977891467511654, 7.906549595538527, 9.523453842978924, 8.818641779869795, 8.549634642627788, 7.570244499072433, 9.747441862225532, 9.153345929661374, 8.969346267804504, 8.612406079564243, 9.296201114144589, 8.92858030974865, 8.499818432412576, 9.11471405396238, 9.739509094342356, 9.013402179479598, 10.115308533012866, 7.90207439463964, 10.041544701047242, 9.250465667545795, 8.119363343194127, 9.000612273216248, 7.8003378737345335, 8.82671607784927, 8.454001014516688, 7.735711478409358, 8.49371278918523, 9.064172574020922, 8.592013950273394, 8.669790407393885, 8.288181716543622, 9.713809885978698, 8.5524710460566, 9.37475555929821, 7.676280855273507, 8.49613686172455, 9.434849231916013, 9.252628951370717, 9.402848179982975, 8.791747173815775, 10.780739871747791, 8.59844768382609, 9.964994645774132, 8.778052367340242, 8.155080926641823, 8.10316024452448]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for dev data"
      ],
      "metadata": {
        "id": "GyCQ_pohoHXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(dev_input_ingredient, pair[0]) # train_input_ingredient etc\n",
        "    target_tensor = tensorFromSentence(dev_output_recipe, pair[1]) # train_output_recipe etc\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "F96lpEGEoI7d"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(dev_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #plt_points_list.append(plot_losses)\n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "Tz-R6g_gopcE"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model3_dev = EncoderRNN(dev_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model3_dev = AttnDecoderRNN(hidden_size, dev_output_recipe.n_words, dropout_p=0.1).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "tp-_Td4rotfP"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_three_plot_loss_dev = trainIters_attn(encoder_model3_dev, decoder_model3_dev, 20000, print_every=1000)\n",
        "print(bm_three_plot_loss_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMdTu1WhozgH",
        "outputId": "f072d1f3-8de3-4793-f35e-4087136d640d"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 29s (- 9m 12s) (1000 5%) 2.9307\n",
            "1m 1s (- 9m 15s) (2000 10%) 2.2705\n",
            "1m 35s (- 8m 59s) (3000 15%) 1.8948\n",
            "2m 8s (- 8m 35s) (4000 20%) 1.8842\n",
            "2m 42s (- 8m 7s) (5000 25%) 1.9037\n",
            "3m 15s (- 7m 37s) (6000 30%) 1.8219\n",
            "3m 49s (- 7m 6s) (7000 35%) 2.0140\n",
            "4m 23s (- 6m 35s) (8000 40%) 2.0003\n",
            "4m 57s (- 6m 3s) (9000 45%) 1.9896\n",
            "5m 32s (- 5m 32s) (10000 50%) 1.8408\n",
            "6m 6s (- 4m 59s) (11000 55%) 2.0475\n",
            "6m 40s (- 4m 27s) (12000 60%) 2.0337\n",
            "7m 15s (- 3m 54s) (13000 65%) 1.9654\n",
            "7m 49s (- 3m 21s) (14000 70%) 2.2313\n",
            "8m 24s (- 2m 48s) (15000 75%) 1.9071\n",
            "8m 59s (- 2m 14s) (16000 80%) 2.0599\n",
            "9m 34s (- 1m 41s) (17000 85%) 1.9675\n",
            "10m 9s (- 1m 7s) (18000 90%) 2.2662\n",
            "10m 44s (- 0m 33s) (19000 95%) 2.1174\n",
            "11m 19s (- 0m 0s) (20000 100%) 2.0616\n",
            "[6.191027992766176, 3.831308244702086, 3.7450869571359364, 2.3366375068268996, 2.6661490125478506, 2.4923623147015443, 1.8042175233652162, 2.323132828237433, 1.8473043970459682, 2.069553048479412, 2.4509528513695935, 2.16982683979414, 2.263036685491146, 2.2273859152894953, 1.6482036007542973, 2.5479111619455024, 2.4628178675406582, 2.0795532864373905, 3.147851925537053, 1.707707816736006, 2.1315882510071096, 1.9739587693666554, 2.103628877081761, 1.5751345986182659, 2.5256394580656774, 1.7422606181110436, 1.0535575828455404, 2.3072076609188414, 1.6665717941670437, 1.8686538591823203, 1.5812433924629852, 2.3202847257569292, 2.193878958438256, 1.9531592478878366, 1.367288745192352, 1.9836080512102594, 1.2722554721425405, 2.4933343737212796, 2.270852666307124, 1.4062272860120997, 1.8668753075287565, 2.1364235445780397, 1.2491669464919681, 2.112900321480108, 1.9223468043185363, 1.631767756424641, 1.9255155438400136, 2.1471549202673557, 2.133967125658374, 1.9105115216499096, 1.343059428711569, 1.5966823757376514, 1.871341495755032, 1.7900564351891066, 2.01174731765664, 2.4245361970720514, 1.1780138518107477, 2.4322744825055995, 1.8051039325670144, 1.7659610254426201, 1.594121463526055, 1.5123907876434175, 2.579642651433147, 2.0760434746916028, 2.319721206264437, 2.109770395098793, 2.217840099734874, 2.137521137844465, 1.4549710220719343, 2.138107878052617, 1.6958531657179652, 1.9768997230190193, 2.273275898754735, 1.6889363963803836, 1.945577182986574, 2.449846173017013, 2.2699800476990095, 2.016764262558831, 1.4859537287919793, 2.1994528012861365, 2.1288258346733193, 1.9002277656451871, 1.6278058578711923, 1.907170367808938, 2.087605084367326, 2.2238434831269918, 1.8649740658598808, 2.411442805311271, 2.0659613222904065, 1.6785822784930762, 1.5120197272202935, 2.096048751828327, 1.614912047163097, 2.6953892491849194, 2.027384414910318, 1.9767905453296626, 1.7080655898637362, 1.6191827981565399, 1.3508588785981699, 1.807551869462609, 2.1527731326606467, 2.4577177879497363, 2.0900316776627887, 2.431303855069187, 1.6332675379348764, 2.3964041506258194, 2.1456003344746333, 1.5908965451224586, 1.711761854424191, 1.8648066122243678, 2.347103296783799, 2.051057555775465, 2.3771371696932553, 1.6968774581204826, 1.779725677195485, 2.1663617603895706, 2.5304439092331767, 1.9466298530941726, 1.8064226258731149, 1.6350256831463745, 1.8211535130098637, 2.0133306566593445, 1.3962306694819602, 1.6551486464630094, 1.6622072563998214, 1.4756258851844364, 1.7626289407991738, 2.3712651011000356, 2.5678083444227804, 2.9282487078667554, 2.112097403450715, 3.0327341946767064, 2.1183465336651235, 1.7509674476784864, 2.442501686125114, 1.9518102755369917, 1.996886016211323, 2.4491029687970465, 2.5164951971552787, 1.94198734078859, 2.0012980659153525, 2.188148596153172, 1.896406612187523, 1.503599634088965, 2.144644466249841, 2.1534761423610593, 2.3848855297156883, 1.887891736590291, 1.7336677394254898, 1.1771936520161919, 2.714354234530699, 2.6606792261456524, 1.5462123129912642, 1.9697371543169486, 2.5941374460640128, 1.7110120513778009, 2.0412648689175814, 1.3900046630795007, 2.3297345454356226, 1.6415486462493094, 2.268339318470105, 1.881750600479437, 1.686634390387204, 2.367796337406062, 1.2946654032434843, 2.1585026607579705, 1.5491190606358005, 1.9778794013852572, 2.1836302337996267, 2.3069533945884078, 2.4326484958183685, 2.01362771637616, 2.5715832335746613, 2.6557829889103255, 1.9876349108898446, 2.2723798891788545, 2.264718430089316, 2.670142034231341, 1.7153164213812175, 2.077783032135978, 2.6304230060903357, 1.5899571799502843, 2.5447576779067256, 1.7349520839648636, 2.167452114267423, 2.020290950234324, 2.5191426510575674, 2.056643740540356, 1.834862183616026, 2.075857196587983, 2.0525868264987777, 1.7943235108234563, 1.2147048010238668, 1.6465324833822905, 2.1089368497200622, 2.3287475309633625, 2.405876260537854, 1.6638009905555027, 2.0563227510306152, 3.3446478497667647]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 3 Evaluation"
      ],
      "metadata": {
        "id": "QsZ5UPuWo30E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ingredient, train_output_recipe, train_pairs = readRecipe_preprocessed(training_data)\n",
        "dev_input_ingredient, dev_output_recipe, dev_pairs = readRecipe_preprocessed(dev_data)\n",
        "test_input_ingredient, testoutput_recipe, test_pairs = readRecipe_preprocessed(test_data)"
      ],
      "metadata": {
        "id": "Ojc5UT-hwBuy"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(test_input_ingredient, pair[0]) # change here according to data set\n",
        "    target_tensor = tensorFromSentence(test_output_recipe, pair[1]) # change here according to data set\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "7BcRUheupFSp"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "cQQztYn8pKZB"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "tyNQvDhYpNhK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_attn(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(test_input_ingredient, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(test_output_recipe.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "6QCwt-vhpUD6"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly_attn(encoder, decoder, n=80):\n",
        "  bm_one_bleu = []\n",
        "  bm_one_meteor = []\n",
        "  matched_words = []\n",
        "  extra_words = []\n",
        "  train_pair_subset = test_pairs\n",
        "\n",
        "  for i in range(n):\n",
        "      pair = random.choice(test_pairs)\n",
        "      #print('>', pair[0])\n",
        "      #print('=', pair[1])\n",
        "      output_words, attention= evaluate_attn(encoder, decoder, pair[0])\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      #print('<', output_sentence)\n",
        "      #print('')\n",
        "\n",
        "      bleu_score = nltk.translate.bleu_score.sentence_bleu(pair[1], output_sentence) \n",
        "      bm_one_bleu.append(bleu_score)\n",
        "\n",
        "      hypothesis = nltk.word_tokenize(output_sentence)\n",
        "      #print(hypothesis)\n",
        "      reference = nltk.word_tokenize(pair[1])\n",
        "      #print(reference)\n",
        "\n",
        "      meteor_score = nltk.translate.meteor_score.single_meteor_score(reference, hypothesis)\n",
        "      #nltk.translate.meteor\n",
        "\n",
        "      bm_one_meteor.append(meteor_score)\n",
        "\n",
        "      matched = 0\n",
        "      extra = 0\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word in reference:\n",
        "          matched += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      matched_words.append(matched)\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word not in reference:\n",
        "          extra += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      extra_words.append(extra)\n",
        "\n",
        "  \n",
        "\n",
        "      train_pair_subset.remove(pair)\n",
        "  \n",
        "  #print(len(train_pair_subset))\n",
        "  \n",
        "  return bm_one_bleu, bm_one_meteor, matched_words, extra_words"
      ],
      "metadata": {
        "id": "H-cjICIApZbZ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model3_test = EncoderRNN(test_input_ingredient.n_words, hidden_size).to(device)\n",
        "decoder_model3_test = AttnDecoderRNN(hidden_size, test_output_recipe.n_words).to(device)"
      ],
      "metadata": {
        "id": "I6qvWs_tpc01"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a few prior functions (readRecipe, indexed, etc) need to be re-run for the below to work\n",
        "\n",
        "\n",
        "bleu, meteor, avg_match, avg_extra = (evaluateRandomly_attn(encoder_model3_test, decoder_model3_test))\n",
        "print(np.mean(bleu))\n",
        "print(np.mean(meteor))\n",
        "print(np.mean(avg_match))\n",
        "print(np.mean(avg_extra))\n",
        "print(avg_extra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux2aGcNJpiqF",
        "outputId": "df2bb1e0-4f9e-4ec1-bc1d-e11dae42474a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.77090744425044e-232\n",
            "0.004703304982528732\n",
            "3.975\n",
            "146.025\n",
            "[150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 147, 150, 150, 150, 149, 150, 150, 148, 150, 149, 150, 150, 149, 150, 150, 150, 6, 150, 150, 150, 150, 147, 149, 149, 150, 150, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 148, 150, 150, 150, 149, 150, 150, 150, 150, 148, 148, 150, 150, 150, 150, 4, 149, 149, 150, 148, 148, 150, 150, 150, 150, 150, 150, 149, 150, 150, 150, 150, 150]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 4 (pre-embedding)"
      ],
      "metadata": {
        "id": "kisFAJb9qeB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUwgyXFwrByv",
        "outputId": "517c722b-83cf-4c8d-96c6-bd37e8d7bbf1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘wiki.multi.en.vec’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sf5bFmdArCUz"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "def load_embeddings(embedding_file, vocab_lang):\n",
        "  embeddings = np.zeros((vocab_lang.n_words, embedding_dim))\n",
        "  with open(embedding_file, encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
        "    for line in f:\n",
        "        word, vect = line.rstrip().split(' ', 1)\n",
        "        vect = np.fromstring(vect, sep=' ')\n",
        "        if word in vocab_lang.word2index:\n",
        "          embeddings[vocab_lang.word2index[word]] = vect\n",
        "  embeddings = torch.from_numpy(embeddings).float()\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "IsYhQWh_rGOu"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ingredient_embedding_train = load_embeddings('wiki.multi.en.vec', train_input_ingredient)\n",
        "recipe_embedding_train = load_embeddings('wiki.multi.en.vec', train_output_recipe)\n",
        "\n",
        "ingredient_embedding_dev = load_embeddings('wiki.multi.en.vec', dev_input_ingredient)\n",
        "recipe_embedding_dev = load_embeddings('wiki.multi.en.vec', dev_output_recipe)\n",
        "\n",
        "ingredient_embedding_test = load_embeddings('wiki.multi.en.vec', test_input_ingredient)\n",
        "recipe_embedding_test= load_embeddings('wiki.multi.en.vec', test_output_recipe)"
      ],
      "metadata": {
        "id": "BuSjoQ0brGv4"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for training data"
      ],
      "metadata": {
        "id": "h7rQo834rufD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(train_input_ingredient, pair[0]) # train_input_ingredient etc\n",
        "    target_tensor = tensorFromSentence(train_output_recipe, pair[1]) # train_output_recipe etc\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "W7g2NFtxrtvi"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, pretrained_embeddings=None):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        # load pretrained embedding if any\n",
        "        if pretrained_embeddings is not None:\n",
        "          self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        else:\n",
        "          self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "R1BB__4srTbQ"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH, pretrained_embeddings=None):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # load pretrained embedding if any\n",
        "        if pretrained_embeddings is not None:\n",
        "          self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        else:\n",
        "          self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size + self.embedding_size, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "hxAGzv7treGu"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(1)\n",
        "    target_length = target_tensor.size(1)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True #if random.random() <= teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "3EpKxu0rrlPl"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #plt_points_list.append(plot_losses)\n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "gL2Wcygmr697"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "encoder_model4_train = EncoderRNN(train_input_ingredient.n_words, embedding_size, hidden_size, pretrained_embeddings=ingredient_embedding_train).to(device)\n",
        "decoder_model4_train = AttnDecoderRNN(embedding_size, hidden_size, train_output_recipe.n_words, dropout_p=0.1, pretrained_embeddings=recipe_embedding_train).to(device)\n"
      ],
      "metadata": {
        "id": "sO7ASH0mrke1"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_four_plot_loss_train = trainIters_attn(encoder_model4_train, decoder_model4_train, 20000, print_every=1000)\n",
        "print(bm_four_plot_loss_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHsAyHa8sB-f",
        "outputId": "70bcada6-07d9-4d19-8495-5e5f5a53e2d2"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 54s (- 17m 20s) (1000 5%) 5.7737\n",
            "1m 50s (- 16m 36s) (2000 10%) 5.1224\n",
            "2m 46s (- 15m 42s) (3000 15%) 4.9791\n",
            "3m 41s (- 14m 45s) (4000 20%) 5.0024\n",
            "4m 36s (- 13m 50s) (5000 25%) 5.0652\n",
            "5m 32s (- 12m 54s) (6000 30%) 5.2555\n",
            "6m 27s (- 11m 59s) (7000 35%) 4.9202\n",
            "7m 22s (- 11m 3s) (8000 40%) 4.8974\n",
            "8m 18s (- 10m 8s) (9000 45%) 4.8792\n",
            "9m 14s (- 9m 14s) (10000 50%) 5.0580\n",
            "10m 10s (- 8m 19s) (11000 55%) 4.9794\n",
            "11m 5s (- 7m 23s) (12000 60%) 4.8156\n",
            "12m 0s (- 6m 28s) (13000 65%) 4.9240\n",
            "12m 56s (- 5m 32s) (14000 70%) 5.0679\n",
            "13m 51s (- 4m 37s) (15000 75%) 4.9221\n",
            "14m 46s (- 3m 41s) (16000 80%) 5.0774\n",
            "15m 41s (- 2m 46s) (17000 85%) 4.8079\n",
            "16m 36s (- 1m 50s) (18000 90%) 4.7685\n",
            "17m 31s (- 0m 55s) (19000 95%) 4.5995\n",
            "18m 25s (- 0m 0s) (20000 100%) 4.8881\n",
            "[7.731001077890396, 6.523137385845184, 6.3691122794151305, 5.60834135055542, 4.880153578519821, 5.552861750125885, 4.99944975733757, 5.503844950199127, 4.826305887699127, 5.7430677211284635, 4.687262317538261, 5.095071071386338, 5.03650063931942, 4.862364371567964, 5.422675231844186, 5.001209152340889, 5.1764262413978575, 5.272917482852936, 4.858709688186646, 5.810672042369842, 4.485584057569504, 4.586994931697846, 5.2859978085756305, 4.769966846108437, 4.801264007687569, 4.980582436323166, 5.0504267168045045, 5.302489235401153, 4.855035607814789, 5.672522250413895, 5.341997843384743, 5.050424423217773, 5.2766001093387604, 4.841400127410889, 5.02756209731102, 4.537483999729156, 5.046377024054527, 5.754444950819016, 4.571275362968445, 4.576085125803948, 4.838120268583298, 5.25525550365448, 5.308570755124092, 5.177462333440781, 5.043384283185005, 4.89626360014081, 5.56947531580925, 4.925349858999252, 4.9224252045154575, 4.71583961725235, 5.341400570273399, 5.220238071680069, 5.766274296045303, 5.420827695131302, 5.515880746841431, 5.536117688417435, 4.9221443116664885, 4.961895876526833, 4.478120181262494, 5.391723800301552, 4.961954288482666, 5.436933394670486, 4.470807331576943, 5.248795481920243, 4.4606150287017226, 4.898631157279015, 4.667284511327743, 5.1241025163978335, 4.770667397975922, 5.162539205774665, 5.032207332253456, 4.9511893171072, 5.101893978640437, 4.527106961011887, 4.49904759645462, 4.922802249193191, 5.356860584020614, 4.513432215452195, 4.588352237902582, 5.481043467521667, 5.296266462802887, 5.03244243003428, 4.648746094703674, 5.061107749305665, 4.558977522850037, 4.885597584992647, 5.503012217283249, 4.54195489436388, 4.413860104978085, 4.849984543323517, 5.403558893203735, 4.519261292815209, 4.126158347129822, 4.786925096809864, 5.499729313850403, 5.207865849733353, 5.59886708855629, 5.244425619840622, 5.075202209949493, 5.1176526844501495, 4.336705442667007, 5.925631411327049, 4.781601887792349, 5.209649072885513, 4.858746285736561, 4.797144961953163, 4.664507350325584, 5.223923548460006, 5.191626539230347, 4.804795503020286, 4.88955066666007, 5.108381086587906, 5.416923691630363, 5.147160358726978, 4.173945568799972, 4.547324084565044, 4.572872646022588, 5.206962265763432, 4.293848209381103, 4.798928587436676, 4.8490594244003296, 4.596939024329186, 5.163647520244122, 4.4703978715837005, 5.068856070637703, 5.095221754014492, 5.120401069594372, 5.053116507530213, 5.145845354497433, 4.676713746786118, 4.7514733248949055, 5.299421299695968, 4.491285094618798, 5.580015039443969, 4.323155974149704, 4.450370121598244, 5.346802750378847, 5.016366446018219, 5.727630939409137, 5.692837172746659, 5.2686791002750395, 4.5093153196573255, 4.85425411619246, 5.412955065369606, 4.59252887904644, 4.989040313363075, 5.180750630181283, 4.944910061359406, 4.581497539430857, 4.887430476546288, 5.155071540474892, 4.918159213215112, 5.026438661813736, 5.408573148250579, 4.877164898104966, 5.363340629637241, 4.494562348276377, 5.191965756267309, 4.703395847082138, 5.634962807297707, 4.642828439623117, 5.745723985135555, 4.379846184253693, 4.295956998989568, 4.662318368367851, 5.131464393734932, 5.033613280057907, 4.694841004610062, 4.831942247152329, 4.660539085119963, 4.837434844970703, 4.659381241798401, 4.148652029037476, 4.6099056935310365, 4.606126646995545, 4.773719714004546, 4.801545068621635, 5.383612543344498, 4.372015317082405, 5.493025024533272, 4.9860335883498195, 5.129617477953434, 4.726040506362915, 4.511723390817642, 4.415937322378158, 4.96802381336689, 4.590450246036053, 4.189202403808013, 4.132939888238907, 4.344650762192905, 4.922161507606506, 4.822386391162873, 5.03976835846901, 4.503228746652603, 5.111460427120328, 4.852141617536545, 4.577960002422333, 5.40657561480999, 4.821784800440073, 4.823499456755817]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for dev data"
      ],
      "metadata": {
        "id": "VPb_apcjsMqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(dev_input_ingredient, pair[0]) # train_input_ingredient etc\n",
        "    target_tensor = tensorFromSentence(dev_output_recipe, pair[1]) # train_output_recipe etc\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "lwR_h8TFsN2l"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = [] #bm_one\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(dev_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    \n",
        "    #plt_points_list.append(plot_losses)\n",
        "    #showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "TWB8Gil6sWFa"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "encoder_model4_dev = EncoderRNN(dev_input_ingredient.n_words, embedding_size, hidden_size, pretrained_embeddings=ingredient_embedding_dev).to(device)\n",
        "decoder_model4_dev = AttnDecoderRNN(embedding_size, hidden_size, dev_output_recipe.n_words, dropout_p=0.1, pretrained_embeddings=recipe_embedding_dev).to(device)\n"
      ],
      "metadata": {
        "id": "wgWmXpfbsZ4q"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_four_plot_loss_dev = trainIters_attn(encoder_model4_dev, decoder_model4_dev, 20000, print_every=1000)\n",
        "print(bm_four_plot_loss_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIUeMDLnsgi3",
        "outputId": "d9f46d5e-e5af-4fa6-913b-56b68bc8837c"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 22s (- 7m 13s) (1000 5%) 2.2980\n",
            "0m 46s (- 6m 59s) (2000 10%) 0.7335\n",
            "1m 9s (- 6m 36s) (3000 15%) 0.5926\n",
            "1m 32s (- 6m 11s) (4000 20%) 0.6581\n",
            "1m 56s (- 5m 48s) (5000 25%) 0.5593\n",
            "2m 18s (- 5m 23s) (6000 30%) 0.5007\n",
            "2m 41s (- 4m 59s) (7000 35%) 0.4989\n",
            "3m 3s (- 4m 35s) (8000 40%) 0.4835\n",
            "3m 26s (- 4m 12s) (9000 45%) 0.4703\n",
            "3m 48s (- 3m 48s) (10000 50%) 0.4680\n",
            "4m 12s (- 3m 26s) (11000 55%) 0.5591\n",
            "4m 36s (- 3m 4s) (12000 60%) 0.4562\n",
            "4m 59s (- 2m 41s) (13000 65%) 0.4511\n",
            "5m 22s (- 2m 18s) (14000 70%) 0.4656\n",
            "5m 45s (- 1m 55s) (15000 75%) 0.4335\n",
            "6m 8s (- 1m 32s) (16000 80%) 0.4408\n",
            "6m 30s (- 1m 8s) (17000 85%) 0.4723\n",
            "6m 53s (- 0m 45s) (18000 90%) 0.4665\n",
            "7m 16s (- 0m 22s) (19000 95%) 0.4705\n",
            "7m 40s (- 0m 0s) (20000 100%) 0.5098\n",
            "[5.587033115029335, 3.992607873380184, 3.0940622281469405, 2.5927647083625196, 1.7638544418615447, 1.6297884878556215, 1.2151205496631154, 1.1686264940202817, 0.9629794051827048, 0.973385331110112, 0.8453582537616603, 0.8920380293731432, 0.5819596720206027, 0.7230627104995073, 0.8249653882868005, 0.7479824670391099, 0.5194884011661633, 0.7083872774482733, 0.6455388930983099, 0.8465774201901514, 0.5978104519201224, 0.5595600458586705, 0.5924280671701126, 0.5711550336710889, 0.6994310173621489, 0.525469693912819, 0.48072506866417825, 0.6151352255709207, 0.6407024390667356, 0.6435569890962324, 0.6412927930274782, 0.49940527337435925, 0.4556378927617311, 0.7490156744568958, 0.49959168884229255, 0.6318015161336461, 0.5622919868936879, 0.8015736391654218, 1.0696693665877648, 0.6705377898436694, 0.6620825269925698, 0.6584562433376892, 0.5979632593353199, 0.8092555908951613, 0.4603383057081192, 0.7121370348489515, 0.4885796562343961, 0.4151277391844906, 0.3152387072138481, 0.474073898345423, 0.5130487221156909, 0.5238640286960845, 0.4525630058098159, 0.4301435595034673, 0.43848121127077777, 0.5299291375861298, 0.5417815844634606, 0.5061000093175084, 0.5510880312958579, 0.5204945570599512, 0.33807836061296487, 0.4120199723447808, 0.5676802009618973, 0.5959750019604325, 0.5019541437982934, 0.4936229336458905, 0.4695996226068655, 0.5285860113980925, 0.548785689720753, 0.532461800828321, 0.4776860842647875, 0.4405602740891834, 0.43719279360989277, 0.41998327214803793, 0.4487920228878784, 0.4300157827938119, 0.5701995800260192, 0.5765899676887238, 0.5610119549922092, 0.47325721508119384, 0.4084029460773672, 0.5383486039119816, 0.6159807661200102, 0.48750132474789554, 0.5409817669208496, 0.4270750203158235, 0.4145138965856245, 0.5128294437747263, 0.3519984102055014, 0.4051219566033387, 0.5649772693583145, 0.4809959383544424, 0.44996743018160484, 0.428903102655604, 0.5093469757347657, 0.5112801162717687, 0.512545639528571, 0.4347461128662462, 0.3374949306255439, 0.4492632962124628, 0.5667166769710684, 0.39425717241583697, 0.5453046202865812, 0.5360852915797818, 0.4206068451570627, 0.6274379660618067, 0.6244405486857499, 0.8556306318662337, 0.6072003494239854, 0.41363339824515577, 0.4261002472436655, 0.5012434381248292, 0.5832685439043069, 0.4985576302725815, 0.42328868470621783, 0.420029104122732, 0.43129729129584066, 0.39443557391593287, 0.40921404483655693, 0.47407257297456, 0.4115350130570278, 0.5683080888577206, 0.3803484755497959, 0.4791422205369804, 0.510884435668495, 0.4187416935835643, 0.2930759220151776, 0.43696341261471844, 0.49393107525154506, 0.5177689745636098, 0.4753215774783666, 0.6132442172150832, 0.4335918094265503, 0.43518682835704114, 0.5643828068722314, 0.4760911765043238, 0.47789325282794837, 0.44891228477906225, 0.40411172204408324, 0.32697792378871765, 0.46359801430483427, 0.525219293627591, 0.42591955251187663, 0.4302639007043193, 0.4028224972378587, 0.40612252446822356, 0.4419290984045793, 0.4703164216682094, 0.39905583381457516, 0.37014130648108223, 0.2962434426777895, 0.355322626873235, 0.502646129424487, 0.3952594023092888, 0.50455818906231, 0.48181437027018775, 0.4408801946584049, 0.5706666733063775, 0.4390731978264921, 0.4211637955657009, 0.39652114352709134, 0.5310580830730237, 0.4181377618224678, 0.4770840747938678, 0.5645539482035815, 0.4399430404303166, 0.4280821528945796, 0.47662720752752874, 0.5341533314541698, 0.4572380112715143, 0.3846515228572025, 0.5179418535293371, 0.35382848170413694, 0.5383629292214782, 0.46834371883980874, 0.42045309787996077, 0.48640635685577766, 0.47557139443376173, 0.5365091118240559, 0.48275353163533397, 0.3645381171085083, 0.44007575059850185, 0.39867465641246386, 0.5850140867500773, 0.4100187652575582, 0.38583359501316344, 0.380151181194582, 0.4490028859152463, 0.5779439190474175, 0.7139012096824072, 0.7273804056371784, 0.7103327971106801, 0.48094270911001724, 0.4885926476493891, 0.5149374630423472, 0.4475902120652004, 0.4224097662122961, 0.4218073718160109, 0.4619335110751671, 0.4222708283798624]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 4 Evaluation"
      ],
      "metadata": {
        "id": "l83829ANskKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #for word in sentence.split(' '):\n",
        "      #print(word)\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(test_input_ingredient, pair[0]) # train_input_ingredient etc\n",
        "    target_tensor = tensorFromSentence(test_output_recipe, pair[1]) # train_output_recipe etc\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "xi5PQj9Asmts"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, pretrained_embeddings=None):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        # load pretrained embedding if any\n",
        "        if pretrained_embeddings is not None:\n",
        "          self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        else:\n",
        "          self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "i7GIUVdGtHhw"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH, pretrained_embeddings=None):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # load pretrained embedding if any\n",
        "        if pretrained_embeddings is not None:\n",
        "          self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        else:\n",
        "          self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size + self.embedding_size, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "M3jigYjntKqV"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_attn(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(test_input_ingredient, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(test_output_recipe.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "Be2WTFxGtPMT"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly_attn(encoder, decoder, n=80):\n",
        "  bm_one_bleu = []\n",
        "  bm_one_meteor = []\n",
        "  matched_words = []\n",
        "  extra_words = []\n",
        "  train_pair_subset = test_pairs\n",
        "\n",
        "  for i in range(n):\n",
        "      pair = random.choice(test_pairs)\n",
        "      #print('>', pair[0])\n",
        "      #print('=', pair[1])\n",
        "      output_words, attention= evaluate_attn(encoder, decoder, pair[0])\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      #print('<', output_sentence)\n",
        "      #print('')\n",
        "\n",
        "      bleu_score = nltk.translate.bleu_score.sentence_bleu(pair[1], output_sentence) \n",
        "      bm_one_bleu.append(bleu_score)\n",
        "\n",
        "      hypothesis = nltk.word_tokenize(output_sentence)\n",
        "      #print(hypothesis)\n",
        "      reference = nltk.word_tokenize(pair[1])\n",
        "      #print(reference)\n",
        "\n",
        "      meteor_score = nltk.translate.meteor_score.single_meteor_score(reference, hypothesis)\n",
        "      #nltk.translate.meteor\n",
        "\n",
        "      bm_one_meteor.append(meteor_score)\n",
        "\n",
        "      matched = 0\n",
        "      extra = 0\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word in reference:\n",
        "          matched += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      matched_words.append(matched)\n",
        "\n",
        "      for word in hypothesis:\n",
        "        if word not in reference:\n",
        "          extra += 1\n",
        "        else:\n",
        "          pass\n",
        "      \n",
        "      extra_words.append(extra)\n",
        "\n",
        "  \n",
        "\n",
        "      train_pair_subset.remove(pair)\n",
        "  \n",
        "  #print(len(train_pair_subset))\n",
        "  \n",
        "  return bm_one_bleu, bm_one_meteor, matched_words, extra_words"
      ],
      "metadata": {
        "id": "ixCX94rktP3L"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "encoder_model4_test = EncoderRNN(test_input_ingredient.n_words, embedding_size, hidden_size, pretrained_embeddings=ingredient_embedding_test).to(device)\n",
        "decoder_model4_test = AttnDecoderRNN(embedding_size, hidden_size, test_output_recipe.n_words, dropout_p=0.1, pretrained_embeddings=recipe_embedding_test).to(device)\n"
      ],
      "metadata": {
        "id": "ZPcuUjfitYmD"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a few prior functions (readRecipe, indexed, etc) need to be re-run for the below to work\n",
        "\n",
        "\n",
        "bleu, meteor, avg_match, avg_extra = (evaluateRandomly_attn(encoder_model4_test, decoder_model4_test))\n",
        "print(np.mean(bleu))\n",
        "print(np.mean(meteor))\n",
        "print(np.mean(avg_match))\n",
        "print(np.mean(avg_extra))\n",
        "print(avg_extra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czJhFwWytpxU",
        "outputId": "92da1f91-bbff-47af-d6b4-459a1d9ebae3"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.1599734533003385e-232\n",
            "0.001858058291858569\n",
            "5.6125\n",
            "144.3875\n",
            "[150, 150, 150, 150, 150, 150, 150, 46, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 80, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 149, 110, 108, 109, 88, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 103, 150, 150, 150, 150, 108, 150, 150, 150, 150]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Analysis"
      ],
      "metadata": {
        "id": "6icDJ4lhS4Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that the models were trained over 2 days so auto-plotting them did not work. Also due to unstable internet, Google Colab kept losing connection and so would lose all variables (see wexample below). This is why the loss points were printed out and manually plotted."
      ],
      "metadata": {
        "id": "4QJMAH1DS_gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bm_four_plot_loss_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "9BPRsAToTXjP",
        "outputId": "d880666f-4d4c-490b-9e35-7dd13d470f45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-0756049119a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm_four_plot_loss_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bm_four_plot_loss_dev' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm_one_plot_loss_train = [10.786120495200157, 9.950586313009262, 10.241034578979015, 9.963319687843322, 10.361198716163635, 10.53011098742485, 10.262799232006072, 9.753206788897515, 10.076771465986967, 10.605815970897675, 10.71353937625885, 11.215103800296783, 8.88976743876934, 8.221422629058361, 9.019803442955016, 7.562892377376556, 6.791876028776169, 7.015565827488899, 6.94422114789486, 5.907635279893875, 7.4156406599283216, 5.966300385594368, 6.505150606632233, 6.888373846411705, 6.2776936447620395, 6.561750299930573, 7.165369225144386, 6.828381645679474, 7.205965890884399, 6.259627103209495, 6.461193196177483, 6.900920432806015, 5.442431173324585, 6.231709743142128, 6.104739159345627, 6.373542736768723, 5.986693646907806, 6.932540010213852, 5.95035195350647, 6.12948149561882, 6.388737882375717, 6.345580179691314, 6.696183793544769, 6.093630378246307, 6.567696802616119, 6.847863655686378, 7.040214301943779, 6.742759449481964, 5.929139213562012, 6.523160938024521, 7.155278351306915, 5.752325201034546, 6.170677388906479, 6.462450781464577, 5.671516935825348, 6.015169190168381, 6.341362793445587, 6.073445037603379, 5.608474037647247, 5.926936019659042, 6.399853564500809, 5.643629393577576, 6.312785124778747, 6.914526582360268, 6.404097232818604, 6.858595186471939, 6.270158710479737, 7.080061680078506, 6.900101093053817, 5.882929881811142, 5.785831556320191, 6.0666132551431655, 5.861957441568375, 6.225740076303482, 6.742385128736496, 6.382067133188247, 6.351310732364655, 5.63214461684227, 6.415814428329468, 5.7524784302711485, 5.7069867539405825, 6.419133102297783, 5.742044560909271, 7.019073053002358, 6.461668881177903, 6.139063693284989, 6.814433507919311, 6.372024626731872, 6.291892083883286, 6.573230383396148, 6.215100462436676, 6.69789818406105, 6.699648212194443, 6.964784972667694, 6.289802672863007, 6.329099764823914, 6.411631183028221, 5.952460774183273, 5.997953515052796, 6.107013443112374, 6.393678412437439, 5.540835101604461, 6.7681114757061005, 6.06776962518692, 6.146684995889664, 5.8959354013204575, 6.3792891490459445, 6.302413464784622, 6.564206562042236, 6.146142055988312, 5.779974380731582, 6.350140089988709, 6.4332261765003205, 5.428883485794067, 6.6256919193267825, 6.1646432161331175, 7.570817598104477, 6.042270090579986, 7.215438997745514, 6.722781615257263, 6.617066694498062, 6.824943350553513, 7.56540755033493, 7.091276557445526, 6.243989436626435, 6.831312251091004, 6.443542233705521, 6.352516185045243, 7.374023357629776, 6.313545140028, 7.233675383925438, 6.406053757667541, 6.4223795509338375, 6.739186061620712, 6.59629652440548, 6.478346297740936, 6.607441904544831, 6.587583436965942, 7.0091281056404116, 6.393697093725205, 6.230496366024017, 6.6259954333305355, 6.5950335597991945, 6.328584510087967, 7.02793642282486, 6.588401352167129, 6.516753573417663, 6.373457320928574, 6.303547253608704, 6.382800576686859, 6.632692211270332, 6.385054277181625, 7.396041789650917, 5.101749290823936, 6.302493838071823, 6.560311008691787, 6.468569304943085, 5.740044907331467, 6.7948519122600555, 5.899004452228546, 6.384416859149933, 5.923948898315429, 6.066186723709106, 6.765795021057129, 6.105852992534637, 6.172299928665161, 5.770175048708916, 6.1824847847223285, 6.078941108286381, 6.176385315656662, 6.3327563345432285, 5.833502802550793, 6.542705268859863, 6.663301991224289, 5.814880599975586, 6.514285361766815, 7.2825670629739765, 5.427788369655609, 6.153260147571563, 6.263811175823212, 6.029586632847786, 5.864763035774231, 6.333080059289932, 5.636003116965294, 5.284861641526223, 5.776406407356262, 5.1473585689067844, 6.969466832280159, 6.191972699165344, 5.789570840597153, 6.049764684438705, 6.3321028625965115, 6.810528032779693, 6.447334469556808, 7.829240328073501, 7.095909551978111, 6.931267845630646, 7.470293300151825, 7.02319269657135, 6.731198434233665]\n",
        "bm_two_plot_loss_train = [9.388982267379761, 7.7777050852775576, 6.829488911032676, 6.969811614751816, 7.605687662363052, 6.577835032939911, 6.535099741220474, 7.29573949098587, 6.7983598709106445, 7.688174868226051, 7.01836980164051, 6.952175240516663, 7.563382929563522, 6.9039197862148285, 6.4862151992321015, 6.996308706998825, 6.961735602617264, 7.402749656438828, 6.085362829566002, 7.131202207803726, 6.594662891626358, 7.886023625135421, 7.7954463768005375, 6.402242485880851, 6.999588726758957, 6.598337265253067, 6.529973151683808, 7.5176193904876705, 6.586673747301102, 6.336730813980102, 7.495337357521057, 7.165498608350754, 6.4505780100822445, 6.163760108947754, 7.575384159088134, 7.208154183030128, 6.725911355018615, 6.685445338487625, 6.761697617769241, 7.437642226219177, 7.034579373002052, 6.4336235469579695, 7.6645242989063265, 6.494566187858582, 8.188588637113572, 7.331823353171348, 6.850116587877274, 6.897375590801239, 7.392452507019043, 7.062586280107499, 6.698193160891533, 7.042383127212524, 6.629448810815811, 7.8528392606973645, 7.460012016296386, 7.867207252979279, 7.909970817565918, 7.465676102638245, 7.298624852299691, 6.85670493721962, 6.599287534356117, 6.488849286437034, 7.548414933681488, 6.342323749661445, 6.794990816116333, 7.768968082666397, 6.746222611665726, 7.579920166730881, 7.093836041390896, 7.432211973667145, 7.400854835510254, 7.128760724663734, 8.05342505723238, 7.695913045406342, 8.486936138272286, 8.394648958742618, 7.899849245548248, 8.512935609817506, 8.368202773332596, 8.572250757217407, 9.254980775117874, 8.310585963726044, 6.841883922815323, 8.58238243728876, 6.940031198859215, 7.998791341185569, 7.509594713449478, 7.496409486532212, 7.536042355298996, 7.484014402627945, 7.526446788907051, 6.939985667467117, 8.220267480015755, 6.928944791555405, 7.177872642874718, 6.814958181977272, 8.25054660320282, 7.587119457125664, 7.3875850594043735, 8.335896764993668, 6.85890208080411, 7.688221904039383, 7.50759224832058, 7.053457851111889, 7.845324138104916, 7.478803125619888, 7.936536396741867, 8.07000170826912, 7.110784638226033, 7.807136694788933, 7.972779787182808, 7.116578612923622, 7.94713967859745, 7.474959335327148, 6.782245986461639, 7.691086109280587, 7.990018355846405, 8.822463009953498, 7.006621455550194, 8.533967742919922, 7.682611246258021, 6.9508682572841645, 7.2170807242393495, 7.425440005660057, 7.224669980406762, 7.09671563744545, 7.121293036341667, 7.887261831760407, 7.125407159328461, 7.230696648359299, 7.376811962127686, 6.657914416193962, 7.435781108736992, 7.705610485076904, 7.840342487096787, 7.510809448361397, 6.701185318231583, 6.805668186545372, 7.407772822380066, 6.922336863279343, 7.588804621696472, 8.125517575144768, 6.307926905155182, 6.642286378145218, 7.000174803137779, 6.371549212932587, 8.058622727394104, 6.430951300859451, 7.364582586586476, 6.947106572389603, 7.372242399454117, 7.4348409199714665, 8.02626456975937, 8.207050879001617, 8.697917311191558, 7.6168472629785535, 7.041642056703568, 7.853544523715973, 7.760836384892464, 7.676482759714126, 8.396893911361694, 7.356567025184631, 8.292323831319809, 7.3608663105964665, 6.520060148239136, 8.222982284426688, 7.430054186582566, 7.377839331626892, 7.975653477907181, 7.465981611609459, 7.0115944766998295, 7.9312744247913365, 6.7870738863945, 7.07470538854599, 7.250877768397332, 7.1141563707590105, 7.307174016833305, 7.887021743059158, 7.449605284929276, 6.981872623860836, 7.593931217193603, 7.710608183145523, 7.247664380669594, 8.05245301157236, 7.613370550870895, 7.756880974769592, 8.269792642593384, 6.987373079657555, 7.974193204641342, 7.587573268413544, 7.532438408136368, 8.696172103881835, 7.589760057032108, 7.142077125906944, 7.449847058653831, 6.46053974211216, 6.719857682585716, 7.504233164191246, 7.731519256234169, 7.277851711809635]\n",
        "bm_three_plot_loss_train = [9.156798487901687, 7.704951445311308, 7.769626179262996, 8.537768945284189, 8.580034768208861, 8.165053878128528, 8.446973920464515, 8.67271901898086, 8.206198983490467, 8.905613913834095, 8.307966793179512, 8.859887516363523, 7.763357540667057, 8.6133424113784, 8.030188243295997, 8.288325197286904, 8.65597889367491, 7.691017134459689, 9.66169031015048, 9.669216325804591, 7.503618690108414, 8.57640478014946, 9.086147911064327, 9.012488676905631, 8.126288202391006, 9.246115454314277, 9.03016643717885, 8.952685780897736, 8.436447951658629, 8.547706653773785, 9.334062929777428, 9.15899856198579, 8.079635779559613, 9.052458660764241, 9.035333109181375, 9.076720024036621, 8.129936296194792, 7.786469534784556, 8.973675734847784, 9.275584366247058, 9.014556703440611, 9.6505286272354, 9.019936406216583, 8.415762968957424, 7.167201608514879, 9.55580063469708, 8.196059511601925, 7.516445641293249, 8.08279662758112, 8.124051308862398, 9.74801394611597, 7.886393552409172, 8.585577910542488, 8.967723658391623, 8.884777930599903, 9.013547024950386, 8.308277772065049, 8.60971262017265, 8.395735231265427, 7.908822255093837, 8.79410008087023, 8.109871785752475, 8.316986619234084, 9.001965430667042, 8.728768455684184, 9.851602224735544, 9.11243737082812, 8.227113161422313, 8.009096753732447, 9.213961088048636, 9.131595673430711, 9.431952715236694, 8.249121002418397, 8.120878470141884, 8.1777596385777, 8.458595501473063, 8.728077433397994, 8.725133145023138, 8.30688656472048, 8.550535515286029, 8.245067321522475, 8.796410826444626, 9.227294180336466, 8.786358974426985, 7.6735829320177436, 7.761296134963632, 9.98028583959298, 9.329863658319228, 7.95557315947488, 8.045425692470213, 8.593818633556365, 8.45627690203488, 8.672213493464515, 9.724273076355376, 9.33039220124483, 8.455355953593074, 8.524823247790337, 10.177170633897186, 8.809091524302056, 8.903950642682611, 7.905028963018931, 8.582544678664998, 10.214938902445137, 7.4855619958788155, 8.722581450045109, 8.631552013908513, 7.953801433444023, 8.61467891484499, 7.38849522347562, 8.896104409811088, 10.439477907551627, 9.915793941318988, 8.964493318379972, 9.08799050888978, 8.668329673707484, 8.377191483052448, 9.34295593192568, 8.187232316972223, 9.032052847720514, 8.83079176902771, 10.121431460449385, 9.878154155855881, 9.298097724325343, 8.32921919329092, 9.584715985879303, 9.140955939599863, 7.926530231311918, 8.515034481883049, 8.163829612356926, 9.142449144728015, 8.519817989149452, 8.739342130050064, 8.43020747391967, 8.428747838176786, 9.173648259788752, 8.919846572756226, 9.319977711639368, 8.714880687089753, 8.484121112556895, 9.037427987620468, 8.932884427309036, 10.172596820890904, 7.630124521337275, 9.425448267119936, 8.458116236467822, 9.86122650663412, 9.119318924993276, 9.060060333078727, 7.957879757732153, 8.88533814670518, 9.463989873882383, 8.693020302005571, 9.102755436002827, 8.401238970011473, 8.977891467511654, 7.906549595538527, 9.523453842978924, 8.818641779869795, 8.549634642627788, 7.570244499072433, 9.747441862225532, 9.153345929661374, 8.969346267804504, 8.612406079564243, 9.296201114144589, 8.92858030974865, 8.499818432412576, 9.11471405396238, 9.739509094342356, 9.013402179479598, 10.115308533012866, 7.90207439463964, 10.041544701047242, 9.250465667545795, 8.119363343194127, 9.000612273216248, 7.8003378737345335, 8.82671607784927, 8.454001014516688, 7.735711478409358, 8.49371278918523, 9.064172574020922, 8.592013950273394, 8.669790407393885, 8.288181716543622, 9.713809885978698, 8.5524710460566, 9.37475555929821, 7.676280855273507, 8.49613686172455, 9.434849231916013, 9.252628951370717, 9.402848179982975, 8.791747173815775, 10.780739871747791, 8.59844768382609, 9.964994645774132, 8.778052367340242, 8.155080926641823, 8.10316024452448]\n",
        "bm_four_plot_loss_train = [7.731001077890396, 6.523137385845184, 6.3691122794151305, 5.60834135055542, 4.880153578519821, 5.552861750125885, 4.99944975733757, 5.503844950199127, 4.826305887699127, 5.7430677211284635, 4.687262317538261, 5.095071071386338, 5.03650063931942, 4.862364371567964, 5.422675231844186, 5.001209152340889, 5.1764262413978575, 5.272917482852936, 4.858709688186646, 5.810672042369842, 4.485584057569504, 4.586994931697846, 5.2859978085756305, 4.769966846108437, 4.801264007687569, 4.980582436323166, 5.0504267168045045, 5.302489235401153, 4.855035607814789, 5.672522250413895, 5.341997843384743, 5.050424423217773, 5.2766001093387604, 4.841400127410889, 5.02756209731102, 4.537483999729156, 5.046377024054527, 5.754444950819016, 4.571275362968445, 4.576085125803948, 4.838120268583298, 5.25525550365448, 5.308570755124092, 5.177462333440781, 5.043384283185005, 4.89626360014081, 5.56947531580925, 4.925349858999252, 4.9224252045154575, 4.71583961725235, 5.341400570273399, 5.220238071680069, 5.766274296045303, 5.420827695131302, 5.515880746841431, 5.536117688417435, 4.9221443116664885, 4.961895876526833, 4.478120181262494, 5.391723800301552, 4.961954288482666, 5.436933394670486, 4.470807331576943, 5.248795481920243, 4.4606150287017226, 4.898631157279015, 4.667284511327743, 5.1241025163978335, 4.770667397975922, 5.162539205774665, 5.032207332253456, 4.9511893171072, 5.101893978640437, 4.527106961011887, 4.49904759645462, 4.922802249193191, 5.356860584020614, 4.513432215452195, 4.588352237902582, 5.481043467521667, 5.296266462802887, 5.03244243003428, 4.648746094703674, 5.061107749305665, 4.558977522850037, 4.885597584992647, 5.503012217283249, 4.54195489436388, 4.413860104978085, 4.849984543323517, 5.403558893203735, 4.519261292815209, 4.126158347129822, 4.786925096809864, 5.499729313850403, 5.207865849733353, 5.59886708855629, 5.244425619840622, 5.075202209949493, 5.1176526844501495, 4.336705442667007, 5.925631411327049, 4.781601887792349, 5.209649072885513, 4.858746285736561, 4.797144961953163, 4.664507350325584, 5.223923548460006, 5.191626539230347, 4.804795503020286, 4.88955066666007, 5.108381086587906, 5.416923691630363, 5.147160358726978, 4.173945568799972, 4.547324084565044, 4.572872646022588, 5.206962265763432, 4.293848209381103, 4.798928587436676, 4.8490594244003296, 4.596939024329186, 5.163647520244122, 4.4703978715837005, 5.068856070637703, 5.095221754014492, 5.120401069594372, 5.053116507530213, 5.145845354497433, 4.676713746786118, 4.7514733248949055, 5.299421299695968, 4.491285094618798, 5.580015039443969, 4.323155974149704, 4.450370121598244, 5.346802750378847, 5.016366446018219, 5.727630939409137, 5.692837172746659, 5.2686791002750395, 4.5093153196573255, 4.85425411619246, 5.412955065369606, 4.59252887904644, 4.989040313363075, 5.180750630181283, 4.944910061359406, 4.581497539430857, 4.887430476546288, 5.155071540474892, 4.918159213215112, 5.026438661813736, 5.408573148250579, 4.877164898104966, 5.363340629637241, 4.494562348276377, 5.191965756267309, 4.703395847082138, 5.634962807297707, 4.642828439623117, 5.745723985135555, 4.379846184253693, 4.295956998989568, 4.662318368367851, 5.131464393734932, 5.033613280057907, 4.694841004610062, 4.831942247152329, 4.660539085119963, 4.837434844970703, 4.659381241798401, 4.148652029037476, 4.6099056935310365, 4.606126646995545, 4.773719714004546, 4.801545068621635, 5.383612543344498, 4.372015317082405, 5.493025024533272, 4.9860335883498195, 5.129617477953434, 4.726040506362915, 4.511723390817642, 4.415937322378158, 4.96802381336689, 4.590450246036053, 4.189202403808013, 4.132939888238907, 4.344650762192905, 4.922161507606506, 4.822386391162873, 5.03976835846901, 4.503228746652603, 5.111460427120328, 4.852141617536545, 4.577960002422333, 5.40657561480999, 4.821784800440073, 4.823499456755817]\n",
        "\n",
        "bm_one_plot_loss_dev = [6.637430275678635, 5.206529125869274, 4.970529796481133, 5.3092136216163635, 5.02588788330555, 5.185980479717255, 4.811426609754562, 4.421689612865448, 4.556514211893082, 4.174174370765686, 4.220243608951568, 4.682569000720978, 4.139259757995606, 4.376613700389862, 4.2085403263568875, 4.1841906440258025, 4.172876106500626, 5.162906517982483, 4.771020272970199, 4.653654606342315, 4.32424861073494, 4.082040550708771, 4.250536863803863, 4.170784854888916, 4.228657038211822, 4.236548355817795, 4.227641342878342, 4.110615764856338, 4.050968589782715, 4.1333548295497895, 3.839680941104889, 4.2785112881660465, 4.1401736557483675, 4.177703944444656, 3.913379529714584, 3.9580821418762206, 3.97474534034729, 4.078816430568695, 4.011299433708191, 3.9974832558631896, 4.1643913400173185, 4.05667058467865, 3.849402816295624, 4.034239387512207, 3.8081082916259765, 3.9945308816432954, 3.9820367920398714, 4.01441749215126, 3.993710036277771, 3.9618930506706236, 4.103118443489075, 3.7871268117427825, 4.104808262586594, 4.079741432666778, 4.036766737699509, 3.9919686627388002, 3.821686488389969, 4.0434087681770325, 4.078786327838897, 3.9686020541191103, 3.870335792303085, 4.16892905831337, 3.9511855673789977, 3.9306881284713744, 3.890139877796173, 4.1038228392601015, 3.9969652462005616, 3.7662725901603697, 3.8821561408042906, 4.069898020029068, 3.877862967252731, 3.980847809314728, 4.073444135189057, 3.8151156520843506, 3.9199306070804596, 4.15512225151062, 4.006737616062164, 3.9217734003067015, 4.048256328105927, 3.869267121553421, 3.9428375649452208, 4.204445216655731, 3.8937279272079466, 3.8789358043670656, 4.1454112637043, 3.8431097769737246, 4.020498180389405, 4.094824645519257, 4.229415261745453, 3.9432816457748414, 3.952895175218582, 4.114044919013977, 3.8587277865409852, 4.098270454406738, 3.9210078179836274, 3.9453900873661043, 4.081620634794235, 3.9580944204330444, 4.043758637905121, 4.106085307598114, 3.966169261932373, 3.9552241826057433, 4.1214946782588955, 3.9206014132499694, 4.126207274198532, 3.9189085268974306, 4.219707927703857, 3.8860293006896973, 3.787059180736542, 4.006200847625732, 4.004117932319641, 3.9969526493549346, 4.162727936506271, 4.178250591754914, 3.9590490007400514, 3.807418521642685, 3.907597143650055, 4.224958908557892, 3.9103271555900574, 3.8868501782417297, 3.876128784418106, 3.9317872500419617, 3.9850260114669798, 3.927089295387268, 3.9273477005958557, 3.87610396027565, 4.035365277528763, 4.024966762065888, 4.064998737573624, 4.002553374767303, 3.926534606218338, 3.697206516265869, 3.740831594467163, 4.043717904090881, 3.9136109697818755, 3.990914189815521, 3.7968749582767485, 3.93832909822464, 3.9660221910476685, 3.9443936455249786, 3.9100868022441864, 3.7748429262638092, 4.044857306480408, 4.116437711715698, 3.9148385953903198, 3.9311125826835633, 3.867720731496811, 4.021632101535797, 4.011937508583069, 3.937513288259506, 3.866223633289337, 3.879595412015915, 4.044353055953979, 4.056820707321167, 4.146285974979401, 4.016704217195511, 3.8624119114875795, 3.957013019323349, 4.10099491238594, 3.928673188686371, 4.044300048351288, 3.988636543750763, 3.910107614994049, 4.012382899522781, 3.7734574234485625, 3.9623131203651427, 3.8605743682384492, 3.7566710114479065, 3.8854898250103, 3.9734052383899687, 4.145643558502197, 4.017852420806885, 4.04347775220871, 3.845279712677002, 3.8967872142791746, 3.807371017932892, 3.9860163259506227, 4.0762493658065795, 3.895347888469696, 3.97465407371521, 4.097620408535004, 4.06104110956192, 3.9596579682827, 3.929441092014313, 4.009430751800537, 3.988149347305298, 4.022362362146378, 3.883375811576843, 4.0749751496315, 4.001915466785431, 3.8957940983772277, 3.961197022199631, 3.9741846895217896, 3.9872403609752656, 4.0376092100143435, 4.091022765636444, 3.846097928285599, 3.980623779296875, 4.083786050081253, 4.097957466840744]\n",
        "bm_two_plot_loss_dev = [7.255357525348663, 5.399887592196465, 5.713572088479996, 5.793259090185165, 5.391277334690094, 4.880471341013909, 5.329641517996788, 5.331783687472344, 5.21092274069786, 5.391756101250649, 5.215547366142273, 5.34411280632019, 5.044066809415817, 5.114803553819656, 5.509711149930954, 6.347118132710457, 5.881783083081245, 5.5123725938797, 5.81731907248497, 5.238312571048737, 5.767440881729126, 5.5073383736610415, 5.473658328056335, 5.561974232196808, 5.930737553834915, 5.481475800871849, 5.029365711212158, 5.544194390773773, 5.28703617811203, 5.549111182689667, 5.365567753314972, 5.457094074487686, 5.181799471378326, 5.416159095168114, 5.592567831873894, 5.54386402964592, 5.415951403379441, 5.511223731338978, 5.447387013435364, 5.106024693846702, 4.838380934298039, 5.42746324300766, 5.053848538994789, 5.377183085680008, 5.290047647953034, 5.287219421863556, 5.193067969083786, 5.197663558721542, 5.598584064841271, 5.22204567193985, 5.48139436006546, 4.9482767868041995, 5.430714339017868, 5.586059844493866, 5.405757966041565, 5.449783281087876, 5.443224566578865, 5.572645452022552, 5.2763015776872635, 5.552357611656189, 5.425538224577903, 5.275468831062317, 5.903756252527237, 5.078338461518288, 5.63023316681385, 5.35487350165844, 4.922378321290016, 5.2981800085306165, 5.685096271038056, 5.568883998990059, 5.248246036171913, 5.216766805052758, 5.779426341056824, 5.229699504375458, 5.448991779983044, 5.250662208795547, 5.359978731870651, 5.624029439687729, 5.262857558727265, 5.429755922555923, 5.366052471399307, 5.194397086501121, 5.026108596771955, 5.547355640530586, 5.078402383327484, 5.250528681278229, 5.100610785484314, 5.179525853395462, 5.51012601852417, 5.39193173289299, 5.258203146457672, 5.863059217333793, 5.474824194908142, 5.273926540613174, 5.315396834611892, 5.659608247280121, 5.399130640029907, 5.3988851702213285, 5.272189881801605, 5.302842937707901, 5.553319050073624, 5.719843801259994, 5.315653696358204, 5.145176058411598, 5.3995974826812745, 5.2967083501815795, 5.056208726465702, 5.05891655266285, 5.476262925863266, 5.54388213455677, 5.565853365659714, 5.46529048204422, 5.036683866381646, 5.478863098621368, 5.36875210762024, 5.686294764280319, 5.441297080516815, 4.944571452140808, 5.512315651476383, 5.286010385751724, 5.19777948975563, 5.5348404103517534, 5.310559420585633, 5.508382807970047, 5.3258159929513935, 5.512976899147033, 5.075251942276955, 5.376520880460739, 5.23883593916893, 5.0028695333004, 5.127181729972363, 5.736433945894241, 5.254048726558685, 5.50217670917511, 5.5203758347034455, 5.2283378446102144, 5.151696152091026, 5.5741207468509675, 5.283387962579727, 5.442416948080063, 5.324783889949321, 5.197398151159287, 5.633257797956467, 5.308692231178283, 5.486853125691414, 5.557641545534134, 5.371790933609009, 5.147042092978954, 5.876966651678085, 5.032553464174271, 5.438488669395447, 5.435045869350433, 5.484960638284683, 5.306094747781754, 4.988251923322678, 5.133098611831665, 5.287788569331169, 5.477934308052063, 5.504687547683716, 5.677437393665314, 5.230454726815224, 5.309036778211594, 5.535175634622574, 5.2596621370315555, 5.45258266210556, 5.463382484912873, 5.367638064622879, 5.501431032419204, 5.126129603087902, 5.602355493307114, 5.54656961530447, 5.1766218739748, 5.702430522441864, 5.4499886173009875, 5.325582234859467, 5.553249132633209, 5.642862888574601, 5.141058091521263, 4.970436109900475, 5.574223361611367, 5.413962647914887, 5.276094633340835, 5.3617184340953825, 5.2136343681812285, 5.3884114742279055, 5.253415340781212, 5.585623693466187, 5.359700818061828, 5.299846060872078, 5.6452753806114195, 5.419801646471024, 5.360870530605316, 5.615453068614006, 5.2168638211488725, 5.287312355041504, 5.669447010755539, 5.059701439142227, 5.175938882827759, 5.36005751490593, 5.581546176671981]\n",
        "bm_three_plot_loss_dev = [6.191027992766176, 3.831308244702086, 3.7450869571359364, 2.3366375068268996, 2.6661490125478506, 2.4923623147015443, 1.8042175233652162, 2.323132828237433, 1.8473043970459682, 2.069553048479412, 2.4509528513695935, 2.16982683979414, 2.263036685491146, 2.2273859152894953, 1.6482036007542973, 2.5479111619455024, 2.4628178675406582, 2.0795532864373905, 3.147851925537053, 1.707707816736006, 2.1315882510071096, 1.9739587693666554, 2.103628877081761, 1.5751345986182659, 2.5256394580656774, 1.7422606181110436, 1.0535575828455404, 2.3072076609188414, 1.6665717941670437, 1.8686538591823203, 1.5812433924629852, 2.3202847257569292, 2.193878958438256, 1.9531592478878366, 1.367288745192352, 1.9836080512102594, 1.2722554721425405, 2.4933343737212796, 2.270852666307124, 1.4062272860120997, 1.8668753075287565, 2.1364235445780397, 1.2491669464919681, 2.112900321480108, 1.9223468043185363, 1.631767756424641, 1.9255155438400136, 2.1471549202673557, 2.133967125658374, 1.9105115216499096, 1.343059428711569, 1.5966823757376514, 1.871341495755032, 1.7900564351891066, 2.01174731765664, 2.4245361970720514, 1.1780138518107477, 2.4322744825055995, 1.8051039325670144, 1.7659610254426201, 1.594121463526055, 1.5123907876434175, 2.579642651433147, 2.0760434746916028, 2.319721206264437, 2.109770395098793, 2.217840099734874, 2.137521137844465, 1.4549710220719343, 2.138107878052617, 1.6958531657179652, 1.9768997230190193, 2.273275898754735, 1.6889363963803836, 1.945577182986574, 2.449846173017013, 2.2699800476990095, 2.016764262558831, 1.4859537287919793, 2.1994528012861365, 2.1288258346733193, 1.9002277656451871, 1.6278058578711923, 1.907170367808938, 2.087605084367326, 2.2238434831269918, 1.8649740658598808, 2.411442805311271, 2.0659613222904065, 1.6785822784930762, 1.5120197272202935, 2.096048751828327, 1.614912047163097, 2.6953892491849194, 2.027384414910318, 1.9767905453296626, 1.7080655898637362, 1.6191827981565399, 1.3508588785981699, 1.807551869462609, 2.1527731326606467, 2.4577177879497363, 2.0900316776627887, 2.431303855069187, 1.6332675379348764, 2.3964041506258194, 2.1456003344746333, 1.5908965451224586, 1.711761854424191, 1.8648066122243678, 2.347103296783799, 2.051057555775465, 2.3771371696932553, 1.6968774581204826, 1.779725677195485, 2.1663617603895706, 2.5304439092331767, 1.9466298530941726, 1.8064226258731149, 1.6350256831463745, 1.8211535130098637, 2.0133306566593445, 1.3962306694819602, 1.6551486464630094, 1.6622072563998214, 1.4756258851844364, 1.7626289407991738, 2.3712651011000356, 2.5678083444227804, 2.9282487078667554, 2.112097403450715, 3.0327341946767064, 2.1183465336651235, 1.7509674476784864, 2.442501686125114, 1.9518102755369917, 1.996886016211323, 2.4491029687970465, 2.5164951971552787, 1.94198734078859, 2.0012980659153525, 2.188148596153172, 1.896406612187523, 1.503599634088965, 2.144644466249841, 2.1534761423610593, 2.3848855297156883, 1.887891736590291, 1.7336677394254898, 1.1771936520161919, 2.714354234530699, 2.6606792261456524, 1.5462123129912642, 1.9697371543169486, 2.5941374460640128, 1.7110120513778009, 2.0412648689175814, 1.3900046630795007, 2.3297345454356226, 1.6415486462493094, 2.268339318470105, 1.881750600479437, 1.686634390387204, 2.367796337406062, 1.2946654032434843, 2.1585026607579705, 1.5491190606358005, 1.9778794013852572, 2.1836302337996267, 2.3069533945884078, 2.4326484958183685, 2.01362771637616, 2.5715832335746613, 2.6557829889103255, 1.9876349108898446, 2.2723798891788545, 2.264718430089316, 2.670142034231341, 1.7153164213812175, 2.077783032135978, 2.6304230060903357, 1.5899571799502843, 2.5447576779067256, 1.7349520839648636, 2.167452114267423, 2.020290950234324, 2.5191426510575674, 2.056643740540356, 1.834862183616026, 2.075857196587983, 2.0525868264987777, 1.7943235108234563, 1.2147048010238668, 1.6465324833822905, 2.1089368497200622, 2.3287475309633625, 2.405876260537854, 1.6638009905555027, 2.0563227510306152, 3.3446478497667647]\n",
        "bm_four_plot_loss_dev = [5.587033115029335, 3.992607873380184, 3.0940622281469405, 2.5927647083625196, 1.7638544418615447, 1.6297884878556215, 1.2151205496631154, 1.1686264940202817, 0.9629794051827048, 0.973385331110112, 0.8453582537616603, 0.8920380293731432, 0.5819596720206027, 0.7230627104995073, 0.8249653882868005, 0.7479824670391099, 0.5194884011661633, 0.7083872774482733, 0.6455388930983099, 0.8465774201901514, 0.5978104519201224, 0.5595600458586705, 0.5924280671701126, 0.5711550336710889, 0.6994310173621489, 0.525469693912819, 0.48072506866417825, 0.6151352255709207, 0.6407024390667356, 0.6435569890962324, 0.6412927930274782, 0.49940527337435925, 0.4556378927617311, 0.7490156744568958, 0.49959168884229255, 0.6318015161336461, 0.5622919868936879, 0.8015736391654218, 1.0696693665877648, 0.6705377898436694, 0.6620825269925698, 0.6584562433376892, 0.5979632593353199, 0.8092555908951613, 0.4603383057081192, 0.7121370348489515, 0.4885796562343961, 0.4151277391844906, 0.3152387072138481, 0.474073898345423, 0.5130487221156909, 0.5238640286960845, 0.4525630058098159, 0.4301435595034673, 0.43848121127077777, 0.5299291375861298, 0.5417815844634606, 0.5061000093175084, 0.5510880312958579, 0.5204945570599512, 0.33807836061296487, 0.4120199723447808, 0.5676802009618973, 0.5959750019604325, 0.5019541437982934, 0.4936229336458905, 0.4695996226068655, 0.5285860113980925, 0.548785689720753, 0.532461800828321, 0.4776860842647875, 0.4405602740891834, 0.43719279360989277, 0.41998327214803793, 0.4487920228878784, 0.4300157827938119, 0.5701995800260192, 0.5765899676887238, 0.5610119549922092, 0.47325721508119384, 0.4084029460773672, 0.5383486039119816, 0.6159807661200102, 0.48750132474789554, 0.5409817669208496, 0.4270750203158235, 0.4145138965856245, 0.5128294437747263, 0.3519984102055014, 0.4051219566033387, 0.5649772693583145, 0.4809959383544424, 0.44996743018160484, 0.428903102655604, 0.5093469757347657, 0.5112801162717687, 0.512545639528571, 0.4347461128662462, 0.3374949306255439, 0.4492632962124628, 0.5667166769710684, 0.39425717241583697, 0.5453046202865812, 0.5360852915797818, 0.4206068451570627, 0.6274379660618067, 0.6244405486857499, 0.8556306318662337, 0.6072003494239854, 0.41363339824515577, 0.4261002472436655, 0.5012434381248292, 0.5832685439043069, 0.4985576302725815, 0.42328868470621783, 0.420029104122732, 0.43129729129584066, 0.39443557391593287, 0.40921404483655693, 0.47407257297456, 0.4115350130570278, 0.5683080888577206, 0.3803484755497959, 0.4791422205369804, 0.510884435668495, 0.4187416935835643, 0.2930759220151776, 0.43696341261471844, 0.49393107525154506, 0.5177689745636098, 0.4753215774783666, 0.6132442172150832, 0.4335918094265503, 0.43518682835704114, 0.5643828068722314, 0.4760911765043238, 0.47789325282794837, 0.44891228477906225, 0.40411172204408324, 0.32697792378871765, 0.46359801430483427, 0.525219293627591, 0.42591955251187663, 0.4302639007043193, 0.4028224972378587, 0.40612252446822356, 0.4419290984045793, 0.4703164216682094, 0.39905583381457516, 0.37014130648108223, 0.2962434426777895, 0.355322626873235, 0.502646129424487, 0.3952594023092888, 0.50455818906231, 0.48181437027018775, 0.4408801946584049, 0.5706666733063775, 0.4390731978264921, 0.4211637955657009, 0.39652114352709134, 0.5310580830730237, 0.4181377618224678, 0.4770840747938678, 0.5645539482035815, 0.4399430404303166, 0.4280821528945796, 0.47662720752752874, 0.5341533314541698, 0.4572380112715143, 0.3846515228572025, 0.5179418535293371, 0.35382848170413694, 0.5383629292214782, 0.46834371883980874, 0.42045309787996077, 0.48640635685577766, 0.47557139443376173, 0.5365091118240559, 0.48275353163533397, 0.3645381171085083, 0.44007575059850185, 0.39867465641246386, 0.5850140867500773, 0.4100187652575582, 0.38583359501316344, 0.380151181194582, 0.4490028859152463, 0.5779439190474175, 0.7139012096824072, 0.7273804056371784, 0.7103327971106801, 0.48094270911001724, 0.4885926476493891, 0.5149374630423472, 0.4475902120652004, 0.4224097662122961, 0.4218073718160109, 0.4619335110751671, 0.4222708283798624]\n",
        "\n"
      ],
      "metadata": {
        "id": "fVEJIJKWTdjl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "def showPlot():\n",
        "    plt.figure(figsize=(8,6), dpi=800)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.5)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    \n",
        "    plt.plot(bm_one_plot_loss_train, color='r', linestyle='dashed', label='Baseline 1 Train')\n",
        "    plt.plot(bm_two_plot_loss_train, color='g', linestyle='dashed', label='Baseline 2 Train')\n",
        "    plt.plot(bm_three_plot_loss_train, color='b', linestyle='dashed', label='Model 3 Train')\n",
        "    plt.plot(bm_four_plot_loss_train, color='y', linestyle='dashed', label='Model 4 Train')\n",
        "\n",
        "    plt.plot(bm_one_plot_loss_dev, color='r', linestyle='solid', label='Baseline 1 Dev')\n",
        "    plt.plot(bm_two_plot_loss_dev, color='g', linestyle='solid', label='Baseline 2 Dev')\n",
        "    plt.plot(bm_three_plot_loss_dev, color='b', linestyle='solid', label='Model 3 Dev')\n",
        "    plt.plot(bm_four_plot_loss_dev, color='y', linestyle='solid', label='Model 4 Dev')\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.04,1), loc=(\"lower left\"))\n",
        "    plt.xlabel('Number of Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "Eh2JYxamUudo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showPlot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1RVRfyokVIFF",
        "outputId": "ab7eb247-951e-44a9-e948-b725c4621ed1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 6400x4800 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Data Statistics"
      ],
      "metadata": {
        "id": "AWdPJa95ZLLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute number of samples/recipes in each data set\n",
        "\n",
        "training_sample_size = len(training_data)\n",
        "dev_sample_size = len(dev_data)\n",
        "test_sample_size = len(test_data)\n",
        "\n",
        "print(training_sample_size, dev_sample_size, test_sample_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMxht9MJZNsf",
        "outputId": "ffa9c928-571f-4e14-94ee-9436d0da47e2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12939 112 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ingredient, train_output_recipe, train_pairs = readRecipe(training_data)\n",
        "dev_input_ingredient, dev_output_recipe, dev_pairs = readRecipe(dev_data)\n",
        "test_input_ingredient, test_output_recipe, test_pairs = readRecipe(test_data)"
      ],
      "metadata": {
        "id": "7owmADoAZZjq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training vocabulary size (ingredient):\" + \" \" + str(train_input_ingredient.n_words))\n",
        "print(\"Dev vocabulary size (ingredient):\" + \" \" + str(dev_input_ingredient.n_words))\n",
        "print(\"Test vocabulary size (ingredient):\" + \" \" + str(test_input_ingredient.n_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH09h-1YZaKf",
        "outputId": "b1300c6b-24ee-47be-b718-b7b715c62230"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training vocabulary size (ingredient): 6475\n",
            "Dev vocabulary size (ingredient): 757\n",
            "Test vocabulary size (ingredient): 645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training vocabulary size (recipe):\" + \" \" + str(train_output_recipe.n_words))\n",
        "print(\"Dev vocabulary size (recipe):\" + \" \" + str(dev_output_recipe.n_words))\n",
        "print(\"Test vocabulary size (recipe):\" + \" \" + str(test_output_recipe.n_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW0lezCTZezw",
        "outputId": "74c660b8-bbbc-4097-9a61-fccba76e8a51"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training vocabulary size (recipe): 15469\n",
            "Dev vocabulary size (recipe): 1502\n",
            "Test vocabulary size (recipe): 1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to compute average lengths of ingredients and recipes respectively."
      ],
      "metadata": {
        "id": "ppABPdAFZgmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computelengths(pair_list):\n",
        "  ing_list = []\n",
        "  recipe_list = []\n",
        "  total_ing = 0\n",
        "  total_recipe_lines = 0\n",
        "\n",
        "  for pair in pair_list:\n",
        "    ing = pair[0].split(' ')\n",
        "    ing_list.append(len(ing))\n",
        "\n",
        "    total_ing += len(ing)\n",
        "\n",
        "    recipe = pair[1].split('.')\n",
        "    recipe_list.append(len(recipe))\n",
        "\n",
        "    total_recipe_lines += len(recipe)\n",
        "\n",
        "  max_ing_length = max(ing_list)\n",
        "  max_recipe_length = max(recipe_list)\n",
        "\n",
        "  avg_ing_length = total_ing/len(pair_list)\n",
        "  avg_recipe_len = total_recipe_lines/len(pair_list)\n",
        "\n",
        "  min_ing_length = min(ing_list)\n",
        "  min_recipe_length = min(recipe_list)\n",
        "\n",
        "\n",
        "  return max_ing_length, max_recipe_length, avg_ing_length, avg_recipe_len, min_ing_length, min_recipe_length"
      ],
      "metadata": {
        "id": "Rw8c5i4bZjNC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(computelengths(train_pairs))\n",
        "print(computelengths(dev_pairs))\n",
        "print(computelengths(test_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNsEQX-_Zm9r",
        "outputId": "76da161f-36c2-4d85-fadd-f828ac6f0f14"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(146, 63, 33.640466805780974, 10.206507458072494, 2, 1)\n",
            "(120, 33, 32.017857142857146, 8.526785714285714, 3, 1)\n",
            "(91, 29, 34.96341463414634, 9.829268292682928, 4, 2)\n"
          ]
        }
      ]
    }
  ]
}